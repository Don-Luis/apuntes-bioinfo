%28/10 - Fátima Sánchez Cabo
\part{Caracterización del genoma mediante NGS}
\chapter{Introducción a la genómica traslacional}
\section{Definición e importancia de la genómica}
La genómica, el estudio integral del ADN y de la estructura, función y dinámica de los genomas, representa un pilar fundamental en la biología moderna. Marcó un cambio de paradigma, pasando de un enfoque reduccionista en biología - donde se estudiaban componentes individuales y de manera aislada - a una perspectiva integradora que analiza las interacciones y relaciones entre los distintos elementos biológicos. Esta transición permitió evolucionar de la genética clásica, basada en hipótesis concretas, hacia la genómica, que integra análisis de datos masivos sin necesidad de preguntas iniciales específicas, aunque sí en constante búsqueda de respuestas biológicas complejas.

En el marco del dogma central de la biología, las “ómicas” representan tres niveles de estudio: la genómica (centrada en el ADN), la transcriptómica (ARN) y la proteómica (proteínas). Este curso se enfoca en la genómica, ya que la información genética determina las funciones bioquímicas y, por ende, los fenotipos de los organismos. Gracias a avances recientes, ahora es posible inferir la función bioquímica de las proteínas directamente a partir de la secuencia de ADN, sin necesidad de técnicas complejas como la cristalización. Además, herramientas de inteligencia artificial pueden predecir la estructura de las proteínas con precisión, acelerando la interpretación de funciones biológicas.

Las proteínas, incluyendo enzimas esenciales, son los elementos funcionales clave en la biología. La secuencia de aminoácidos en una cadena polipeptídica define sus propiedades funcionales, y, por tanto, conocer la secuencia genética subyacente (el ADN) facilita predecir la función de una proteína. Aunque determinar experimentalmente las propiedades de una proteína es complejo, la secuenciación genómica ha simplificado enormemente este proceso.

La mejora en tecnologías de secuenciación impulsó el \textbf{Proyecto Genoma Humano}, que logró identificar entre 20,000 y 25,000 genes y determinar la secuencia de los aproximadamente 3 mil millones de pares de bases del genoma humano. Este proyecto también fomentó la creación de bases de datos y herramientas para el análisis de datos genómicos, además de abrir el debate sobre los aspectos éticos, legales y sociales (conocidos como ELSI, por sus siglas en inglés), que siguen siendo temas vigentes y complejos en la actualidad.

\subsection{Evolución de la bioinformática en la genómica}
La bioinformática ha crecido a la par de la genómica en múltiples niveles. Inicialmente, era una \textbf{disciplina} incipiente y se desarrollaba como apoyo experimental; sin embargo, ha evolucionado hasta convertirse en un campo esencial que impulsa la investigación. En cuanto a su \textbf{material, los datos,} la bioinformática ha tenido que adaptarse al fenómeno del big data, pasando de manejar cantidades limitadas de datos a enfrentar volúmenes masivos, propios de la genómica actual. Paralelamente, el \textbf{rol de los bioinformáticos} se transformó, pasando de ser técnicos a científicos de datos y académicos altamente reconocidos en la industria y en la investigación.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.5\textwidth]{figs/history-bioinfo.png}
\caption{Breve historia de la bioinformática en tres niveles: como disciolina, como material que utiliza y como las personas que trabajan en ella. Evolución desde 1980 hasta 2020.}
\end{figure}

\section{Avances tecnológicos en secuenciación}
Existen distintos tipos de tecnologías de secuenciación, comúnmente clasificadas en tres generaciones: la primera generación (first generation), la segunda o Next Generation Sequencing (NGS) y la tercera generación. Las dos primeras generaciones se enfocan en la secuenciación de fragmentos cortos de ADN, mientras que la tercera generación permite la lectura de fragmentos largos, facilitando el ensamblaje completo de genomas. Actualmente, uno de los mayores desafíos tecnológicos es detectar variantes de baja frecuencia y realizar secuenciaciones de ADN en células individuales (single-cell sequencing), lo cual tradicionalmente se hacía de forma masiva (“bulk”).

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/sequencing-generations.png}
\caption{Las tres generaciones de secuenciación y su forma de actuar.}
\end{figure}

A medida que el costo de la secuenciación ha disminuido y la capacidad de almacenamiento ha mejorado desde 1990, los datos generados también han crecido exponencialmente. En un experimento de secuenciación, los costos abarcan tanto la secuenciación en sí como el procesamiento bioinformático, el reporte y el almacenamiento de los datos. La comunidad científica y muchos journals requieren que los datos de proyectos financiados públicamente estén disponibles en bases de datos accesibles, lo que asegura la transparencia y el acceso a esta información valiosa. Para obtener una cobertura de calidad, el ADN suele secuenciarse al menos 30 veces, lo que genera archivos de gran tamaño, como los archivos FastQ, que almacenan información de secuencia y calidad para cada base.

\section{Procesos de llamada y priorización de variantes}
Los datos de secuenciación se procesan en pipelines bioinformáticas que comienzan con archivos FastQ normalmente comprimidos y pasan por varias etapas: control de calidad, alineamiento y llamada de variantes (variant calling). Las variantes identificadas pueden incluir cambios de nucleótidos, variaciones en el número de copias de segmentos genómicos (copy number variation) o reordenamientos estructurales.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/bioinfo-pipeline.png}
\caption{Esquema de la pipeline que se sigue en bioinformática para la llamada de variantes.}
\end{figure}

La priorización de variantes se basa en factores como el impacto funcional, la frecuencia alélica en la población y la asociación con enfermedades. Sin embargo, muchas variantes requieren validación experimental, frecuentemente en modelos animales como ratones, para corroborar su relevancia funcional. El proceso de filtrado inicial se enfoca en variantes en exones de genes candidatos, analizando su frecuencia, patogenicidad y modelo de herencia; en caso de no hallarse variantes relevantes, se amplía el análisis a variantes oligogénicas o no codificantes.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.5\textwidth]{figs/variant-priorization.png}
\caption{Ejemplo de la priorización de variantes.}
\end{figure}

\section{Genómica en medicina de precisión}
La genómica ha transformado el enfoque de la medicina de precisión, permitiendo identificar enfermedades con bases genéticas, ambientales o una combinación de ambas. Algunas variantes genéticas confieren una predisposición a enfermedades sin ser causantes directas, lo cual es crucial para inferir relaciones causales y acelerar ensayos clínicos mediante la integración de grandes volúmenes de datos. Estas variantes pueden clasificarse en germinales (heredadas) o somáticas (adquiridas).

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.5\textwidth]{figs/genetic-environment.png}
\caption{Representación gráfica de la relación entre enfermedades con base genética, ambientales o una mezcla de ambas.}
\end{figure}

En medicina de precisión, la genómica es solo una capa de datos entre muchas. Para una comprensión holística de la salud y la enfermedad, es necesario combinarla con información de otras “ómicas” como la transcriptómica, epigenómica, proteómica, metabolómica, y datos de microbioma. Además, los datos clínicos y epidemiológicos también forman parte del ecosistema de \textbf{Big Data Biomédico}, que actualmente se maneja mediante técnicas avanzadas de computación en clusters HPC, computación en la nube y algoritmos de GPU.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/bigger-picture-bioinfo.jpg}
\caption{Esquema representando el dibujo general de la bioinformática.}
\end{figure}

Varias bases de datos públicas permiten estudiar la transición entre salud y enfermedad. El estudio de Farmingham, por ejemplo, lleva más de 70 años recolectando datos de factores de riesgo cardiovascular en más de 15,000 participantes. En Reino Unido, el Biobank y, en Estados Unidos, la iniciativa All of Us, también representan recursos de gran envergadura. En España, el CNIC (Centro Nacional de Investigaciones Cardiovasculares) realiza el estudio PESA (Progression of Early Subclinical Atherosclerosis), que ha contribuido a identificar factores predictivos de aterosclerosis subclínica mediante el estudio multiómico, generando nuevos indicadores con un mayor poder predictivo de la formación de placas de colesterol.

\subsection{Epigenética y la medición de la edad biológica}
El perfil de metilación del ADN es un factor epigenético que puede modificar la expresión genética y se ha utilizado para calcular la “edad biológica” o epigenética de una persona, lo que puede servir como predictor de esperanza de vida y salud. Al comparar estos perfiles con la edad cronológica, sexo y otros factores, se obtiene información sobre el envejecimiento y el riesgo de enfermedades, facilitando el desarrollo de estrategias de salud personalizadas.

\section{Resumen}
La genómica ha liderado una revolución científica en el siglo XX, evolucionando desde el estudio de componentes individuales hasta una perspectiva integral de sistemas biológicos y de investigación basada en datos masivos. La bioinformática se ha convertido en una disciplina central en el análisis genómico y predicción de estructuras proteicas, impulsada por el Proyecto Genoma Humano y el desarrollo de tecnologías de secuenciación. Los avances actuales buscan no solo la secuenciación del ADN, sino también la integración de estos datos con datos epidemiológicos y moleculares para obtener una comprensión más profunda de la salud y la enfermedad. Así, el Proyecto Genoma Humano fue decisivo para sentar las bases de tecnologías de secuenciación, el desarrollo de la bioinformática en sí y el uso social e industrial de los datos ómicos.

La identificación de características genómicas relevantes causales de rasgos/enfermedades se basa en la anotación de variantes en bases de datos y en estudios poblacionales: hay margen de mejora y un gran éxito de la ciencia colaborativa. Hoy en día, los principales proyectos tratan no sólo de secuenciar el ADN, sino de integrar esta información con datos epidemiológicos y otros datos moleculares para comprender mejor la salud y la enfermedad.
Las enfermedades, en función de su base genética, pueden clasificarse en monogénicas (mendelianas), oligogénicas (ej., cardiopatías familiares) y complejas (evaluadas mediante puntuaciones de riesgo poligénicas). Esta clasificación permite avanzar en la medicina de precisión, abordando enfermedades desde su origen genético para ofrecer intervenciones de salud más efectivas y personalizadas.

%30/10 - Álvaro Serrano
\chapter{Métodos de secuenciación}
La secuenciación permite pasar de la información contenida en el ADN a un dominio digital mediante una representación abstracta. 

El primer método de secuenciación fue el \textbf{método Maxam-Gilbert}, que utilizaba un marcador en el extremo 5' del ADN. En este proceso, el ADN se trataba con diferentes compuestos químicos para provocar rupturas específicas en función de cada base nitrogenada. Los fragmentos resultantes se separaban en un gel de acrilamida mediante electroforesis, y se revelaban mediante autoradiografía de rayos X. La secuencia se deducía observando el patrón de bandas resultante.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.3\textwidth]{figs/maxam-gilbert.png}
\caption{\textbf{Principio de la secuenciación Maxam-Gilbert}: Se llevaron a cabo cuatro reacciones separadas para la degradación de bases en un fragmento de ADN monocatenario: A+G, G, C+T y C. Se obtienen fragmentos de ADN de diferente longitud tras la degradación de las bases y la escisión del esqueleto de azúcar-fosfato. Los productos se cargan en cuatro pocillos separados de un gel de poliacrilamida. La secuencia se lee de abajo a arriba como GTATGC. Si se encuentra una G frente a un hueco en el gel, se confirma que se trata de 5-metilcitosina en la cadena molde.}
\end{figure}

Otro método clave es el de \textbf{terminación de cadena, o método de Sanger}. Este utiliza deoxinucleótidos modificados, que tienen un átomo de hidrógeno en el grupo 2' de la pentosa, en lugar de un grupo hidroxilo (OH). Esto impide la unión del extremo 5' al 3', deteniendo así la extensión de la cadena de ADN. El resultado es una mezcla de fragmentos de distintos tamaños, los cuales se marcan con isótopos radioactivos o, en versiones más modernas, con fluoróforos. La secuencia se obtiene mediante detección de colores en una única reacción, simplificando el análisis. La clave de este método \marginpar[\footnotesize Pregunta examen] \ es el uso de dideoxinucleótidos, que interrumpen la actividad de la ADN polimerasa, permitiendo detener la cadena de manera controlada.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/sanger.png}
\caption{\textbf{El método de secuenciación Sanger en 7 pasos.} (1) El fragmento de dsADN se desnaturaliza en dos fragmentos de ssADN. (2) Un fragmento de ssADN se multiplica en millones de copias. (3) Se une un cebador que corresponde a un extremo del fragmento. (4) Los fragmentos se añaden a cuatro soluciones de polimerasa. Cada solución contiene los cuatro tipos de bases pero sólo un tipo de nucleótido de terminación. (5) La cadena crece hasta que se añade aleatoriamente un nucleótido de terminación. (6) Los fragmentos de dsADN resultantes se desnaturalizan para obtener una serie de ssADN de distintas longitudes. (7) Los fragmentos se separan por electroforesis y se lee la secuencia.}
\end{figure}

El primer secuenciador automático fue el ABI370, capaz de secuenciar hasta 5000 bases al día. Sin embargo, se necesitarían aproximadamente 16,000 años para secuenciar todo el genoma humano usando esta tecnología. Este secuenciador innovador reemplazaba los geles por electroforesis capilar y un detector de fluorescencia. Durante el Proyecto Genoma Humano en los años 90 y 2000, desarrollado en colaboración entre el sector público y privado, se introdujeron mejoras significativas a los secuenciadores, como el modelo ABI377, que empleaba varios capilares para incrementar la eficiencia. Sin embargo, la secuenciación de regiones altamente repetitivas del genoma, como los telómeros y centrómeros, fue compleja, y la primera descripción completa del genoma humano fue publicada hace apenas un año.

\section{Métodos de secuenciación empleados en el Proyecto Genoma Humano}
Los métodos que se utilizaron en el proyecto fueron los siguientes:
\begin{itemize}
\item \textbf{Hierarchical Shotgun:} En este método, el ADN se clona en fragmentos más pequeños usando enzimas de restricción. Estos fragmentos se solapan y forman contigs, los cuales se ensamblan progresivamente para reconstruir la secuencia original.
\item \textbf{Whole-genome Shotgun:} Similar al método anterior, pero se realiza directamente sobre el genoma completo en lugar de partir de cromosomas bacterianos. El ADN se clona en bacterias, se fragmenta y se ensamblan los contigs mediante solapamiento.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/HGP-sequencing.png}
\caption{\textbf{Estrategias de secuenciación en el Proyecto Genoma Humano.} (Izquierda) La estrategia de hierarchical shotgun (HS) consiste en descomponer el genoma en un camino de mosaico de clones BAC (bacterial artificial chromosome) superpuestos, realizar la secuenciación en cada BAC y volver a ensamblarlo, y luego fusionar las secuencias de clones adyacentes. El método tiene la ventaja de que todos los contigs de secuencias y scaffolds derivados de un BAC pertenecen a un único compartimento con respecto al anclaje al genoma. (Derecha) La estrategia WGS (Whole-genome shotgun) consiste en secuenciar todo el genoma e intentar reensamblar toda la colección. Con el método WGS, cada contig y scaffold es un componente independiente que debe anclarse al genoma. En general, muchos scaffolds no pueden anclarse sin esfuerzos dirigidos. (Los contigs son bloques contiguos de secuencia; los scaffolds son conjuntos de contigs unidos por lecturas emparejadas de ambos extremos de un inserto plasmídico).}
\end{figure}

La electroforesis capilar, usada en ambos métodos, permite separar fragmentos de ADN de diferentes tamaños a través de un capilar con un detector de fluorescencia, logrando una lectura precisa de aproximadamente 500 pares de bases por fragmento. Con el tiempo, los costos de secuenciación disminuyeron gracias a avances en técnicas posteriores al método de Sanger.

\section{NGS: la siguiente generación de tecnología de secuenciación del ADN}
La secuenciación de segunda generación o Next-Generation Sequencing (NGS) permite una secuenciación paralela y masiva, también conocida como \textbf{high-throughput sequencing}. Los principales métodos NGS incluyen 454 Roche, Solexa Illumina, ABI/SOLiD, Complete Genomics, Pacific Biosciences, Ion Torrent y Oxford Nanopore.

\subsection{Preparación de librerías de NGS}
Las librerías de secuenciación se preparan fragmentando el ADN y generando secuencias que luego se amplifican y procesan en el secuenciador, obteniendo las lecturas o reads. Estas librerías se amplifican clonalmente mediante tres métodos:
\begin{itemize}
\item \textbf{Beads:} pequeñas bolitas recubiertas de primers, donde el ADN se adhiere y se amplifica.
\item \textbf{Fase sólida:} el ADN se adhiere a una superficie de cristal donde se amplifica.
\item \textbf{Nanobolas:} se produce un ovillo de ADN amplificado en forma circular, que se adhiere a una placa metálica funcionalizada (con grupos funcionales) para secuenciación.
\end{itemize}

La secuenciación NGS utiliza un gran número de moléculas idénticas, permitiendo una secuenciación paralela de alta eficiencia y alto rendimiento o high-throughput. La característica de la segunda generación es que utiliza la molécula de ADN original y, sobre ella, la amplifica, es decir, la utiliza como molde para generar muchas moléculas iguales. 

\subsection{Clasificación de NGS: secuenciación por síntesis y por ligación}
Los métodos de secuenciación de segunda generación se pueden clasificar en secuenciación por síntesis (con la enzima polimerasa) o secuenciación por ligación (con la enzima ligasa).

\begin{itemize}
\item \textbf{Secuenciación por síntesis (SBS)}
\begin{itemize}
\item \textbf{Ciclo de terminación reversible (CRT):} una evolución del método Sanger. Se utiliza ADN unido a beads o cristales y se añaden dNTPs modificados con el grupo 3’ OH bloqueado, limitando así la duplicación de la polimerasa. Cada ciclo implica la incorporación de un nucleótido, seguido de una señal fluorescente específica del nucleótido unido. Posteriormente, el grupo OH se desbloquea con un químico de lavado para que el proceso continúe. La señal que se detecta no es de un único nucleótido, si no del conjunto de nucleótidos del cluster, que debido a la amplificación clonal, debería ser la misma señal amplificada. Esto se realiza por el límite de detección de fluorescencia de los microscopios. Además, la placa con los moldes tiene en los límites unos marcadores que permiten que el microscopio se enfoque a la altura a la que debe. 

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/secuenciacion-terminacion-ciclica-reversible.jpg}
\caption{\textbf{Secuenciación por terminación cíclica reversible:}
Esta metodología se basa en la utilización de nucleótidos marcados con fluoróforos en una reacción de síntesis de ADN. Cada vez que uno de estos nucleótidos se incorpora a la cadena, el sistema toma una captura y registra de qué tipo de nucleótido se trata. Una vez tomada la captura, se eliminan los fluoróforos de los nucleótidos que se han incorporado y se continúa la síntesis de la cadena con nuevos nucleótidos marcados. }
\end{figure}

Una vez terminada la secuenciación, se utiliza como primer para secuenciar la cadena contraria. Esto se debe a que el microscopio va enfocando peor y se pierde calidad. Cada señal emitida por el fluoróforo se conoce como call o llamada. Cada call tiene una confident score de Q, que se calcula mediante la fórmula $Q = - 10 \cdot log_{10} P $. Por tanto, si Q es 30, P sería $10^{-3}$, representando P la probabilidad de error. La información que se obtiene en el archivo es la secuencia obtenida con un valor Q asociado codificado en ASCII. 

Los microscopios se clasifican en microscopios de 4 canales y de 2 canales. Los microscopios de 4 canales tienen una mayor calidad al poder distinguir cada uno de los nucleótidos, mientras que los de 2 canales utilizan la combinación de dos fluoróforos: se detecta verde, rojo, la combinación entre verde y rojo, y la ausencia de fluorescencia. Esto último es algo arriesgado, ya que algunos nucleótidos podrían perder el fluoróforo y se consideraría ausencia de fluorescencia. No obstante, estos microscopios de 2 canales, pese a tener una peor calidad, son más rápidos y baratos. Respecto al secuenciador, hay varios tipos, por lo que al elegir uno se tendrá que tener cuenta el caso de uso y el dinero disponible (la página de Illumina tiene tablas comparativas para elegir el mejor secuenciador para cada caso). 

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/microscope-channels.png}
\caption{Comparación entre los microscopios de 4 y de 2 canales.}
\end{figure}

Las ventajas de la secuenciación CRT es que es la que produce la mayor cantidad de secuencias secuenciadas a la vez (mayor throughput). La desventaja es el límite que puede secuenciar, que es en torno a 150 bases por cada extremo. 

\item \textbf{Adición de nucleótidos simple (SNA):} en cada ciclo se añade un solo tipo de nucleótido, detectando su incorporación. Este método es sensible a los homopolímeros (repeticiones del mismo nucleótido), lo que puede generar problemas de fase si la señal no es proporcional al número de nucleótidos añadidos.
\begin{itemize}
\item \textbf{Pirosecuenciación:} emplea pirofosfato liberado en la síntesis de ADN. Debido a su enlace de alta energía, la acción de la pirofosfatasa acoplada a la luciferasa produce que se emita una señal de luz proporcional al número de nucleótidos añadidos. Este método es rápido, económico y preciso, aunque presenta limitaciones con secuencias largas debido al cambio de fase en el momento en el que se produzca un error. La calidad de la secuenciación es Q45 (99,997\%). 

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.5\textwidth]{figs/pirosecuenciacion.png}
\caption{Esquema de la pirosecuenciación, tecnología que permite determinar el orden de una secuencia de ADN mediante luminiscencia.}
\end{figure}

\item \textbf{Ion Torrent proton detection:} mide el cambio de pH (cambio de potencial) que ocurre al liberar un protón durante la polimerización del ADN. Al final de cada ciclo es necesario lavar para evitar la señal cruzada. La técnica es económica y ampliamente utilizada en hospitales, pero presenta desafíos con secuencias largas debido a la falta de proporcionalidad en la señal en secuencias con regiones muy repetitivas (si se unen dos nucleótidos en lugar de uno, la señal es proporcional a los dos, pero cuando se unen 50 nucleótidos, el cambio de potencial no es proporcional a los 50).

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/Ion-torrent-sequencing.jpg}
\caption{\textbf{Secuenciación por Ion Conductor (Ion Torrent Sequencing):} 
Se trata de una estrategia que se basa en la detección de las modificaciones en el pH que se producen en la síntesis de ADN. Para ello, se van incorporando nucleótidos a una cadena de ADN, provocando que se libere un protón (H+) en la reacción y, por tanto, que se vea modificado el pH. Para poder diferenciar cuál de los cuatro tipos de nucleótidos se ha introducido en cada posición de la secuencia, se repiten varios ciclos, cada uno de ellos, con la adición de un único tipo de nucleótido. }
\end{figure}

\end{itemize}
\end{itemize}

\item \textbf{Secuenciación por ligación (SBL)}
\begin{itemize}
\item \textbf{Secuenciación por SOLiD:} Este método emplea sondas de ligación con dos bases complementarias a la base que se secuencia. En cada ciclo, una ligasa une una sonda marcada con un fluoróforo y luego se elimina la fluorescencia para repetir el ciclo, generando datos precisos, aunque menos comunes en la práctica. Se van mapeando dos nucleótidos a la vez, dejando un espacio de 3 nucleótidos. Por ello, se repite cinco veces añadiendo espaciadores que permitan el solapamiento de las lecturas.

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/solid-sequencing.jpg}
\caption{\textbf{Ilustración del método de secuenciación por ligación utilizando la plataforma SOLiD.} (a) Esquema de los diferentes pasos seguidos por el método SOLiD de ligadura por cuatricromía: hibridación de primers, ligadura selectiva de las sondas, obtención de imágenes por cuatricromía y escisión de la sonda. El ciclo SOLiD se repite nueve veces más. El producto de extensión se elimina y la plantilla se reajusta con un cebador complementario a la posición n -1 para una segunda ronda de ciclos de ligación. (b) Se realizan cinco rondas de reajuste del cebador para cada etiqueta de secuencia. Mediante el procedimiento de reajuste de cebadores, prácticamente todas las bases se consultan en dos reacciones de ligación independientes con dos cebadores diferentes.}
\end{figure}

\item \textbf{Complete Genomics (Nanoballs, BGI):} Amplifica ADN mediante rolling circle para formar ovillos, que luego se hibridan en una placa. Las sondas fluorescentes hibridan de forma iterativa para secuenciar el ADN. Este método permite una alta densidad de secuencias pequeñas, teniendo así una precisión muy alta. No obstante, permite secuenciar lecturas pequeñas y, al final, se utilizan distintos adaptadores a los que se unen las sondas, permitiendo aumentar el througput. Hay partes de la tecnología que no se conocen y está principalmente disponible en China.
\end{itemize}
\end{itemize}

\subsection{Limitaciones y desafíos en NGS}
La NGS de segunda generación presenta una tasa de error de Q25-Q35 y ciertas limitaciones:
\begin{itemize}
\item \textbf{Lecturas cortas} generan dificultades en el ensamblaje de genomas completos y en la identificación de variantes estructurales.
\item \textbf{Errores de secuenciación} especialmente en regiones complejas y repetitivas, como secuencias AT/GC (SBS) y homopolímeros (SNA).
\item \textbf{Sesgo de amplificación} algunas regiones se amplifican mejor que otras, afectando la uniformidad en las lecturas.
\item \textbf{Alto coste de los equipos}
\item \textbf{Fenómeno de la cadena retrasada} cuando no se incorpora un nucleótido, produciendo un descabalgamiento del ciclo de lectura real y el ciclo de lectura en el que creemos que estamos.
\item \textbf{Persistencia de errores en los cluster} al producirse un error en el cluster, el error se queda a lo largo de la secuenciación.
\item \textbf{Cambios epigenéticos}
\end{itemize}

\section{Resumen}
La secuenciación ha cambiado la forma de hacer y entender la biología. La secuenciación de segunda generación o NGS permite secuenciar millones de moldes de ADN al mismo tiempo. Generalmente, el molde de ADN es amplificado clonalmente, y las llamadas se hacen mediante el consenso de los moldes clonales. Hay dos tipos de secuenciación NGS: por síntesis con la polimerasa o por ligación (SOLiD y Nanoballs). Hay dos tipos de secuenciación por síntesis. La adición simple de nucleótidos (pirosecuenciación 454 y Ion Torrent) añade un dNTP distinto en cada ciclo, pero tiene problemas con moldes homopoliméricos. La terminación cíclica reversible (Illumina) añade todos los dNTP en cada ciclo y secuencia la misma posición en el molde, pero puede sufrir de desfase.
%Importante a quedar claro: diferencia entre secuenciación por síntesis y por ligación, y dentro de ellos la diferencia entre el método CRT y SNA. Los métodos de ligación hay que saber que existen, pero no es habitual trabajar con ellos. 

\section{Quizz}
\begin{enumerate}
\item Which of the following NGS platforms offers the highest accuracy?
\begin{itemize}
\item Ion Torrent
\item 454
\item Illumina
\item SOLiD
\end{itemize}

Answer: Illumina

\item What is the reversible chain termination method (CRT)?
\begin{itemize}
\item A method that uses modified nucleotides to stop DNA synthesis
\item A method that involves the use of anchors and fluorescent probes
\item A sequencing process based on detecting pH changes
\item A real-time PCR technique
\end{itemize}

Answer: A method that uses modified nucleotides to stop DNA synthesis

\item Which sequencing method employs PCR amplification and ddNTP?
\begin{itemize}
\item Maxam-Gilbert
\item Ion Torrent
\item Sanger
\item Nanoballs
\end{itemize}

Answer: Sanger

\item What is a common problem in second generation sequencing methods?
\begin{itemize}
\item Low cycling efficiency
\item Difficulty detecting homopolymers
\item Low precision in GC regions
\item Very long execution times
\end{itemize}

Answer: Difficulty detecting homopolymers

\item What NGS technology allows real-time sequencing?
\begin{itemize}
\item 454
\item SOLiD
\item Illumina
\item PacBio
\end{itemize}

Answer: PacBio

\item What achievement was reached with the Human Genome Project (HGP)?
\begin{itemize}
\item Sequencing of the complete human genome
\item Sequencing of the mouse genome
\item The first automated sequencing
\item Creation of the nanoball sequencing method
\end{itemize}

Answer: Sequencing of the complete human genome

\item What technology uses circle displacement amplification to generate nanoballs?
\begin{itemize}
\item PacBio
\item SOLiD
\item Illumina
\item BGI
\end{itemize}

Answer: BGI

\item What was the first NGS instrument developed?
\begin{itemize}
\item Illumina
\item Ion Torrent
\item 454
\item SOLiD
\end{itemize}

Answer: 454

\item What error is common in sequencing based on the nucleotide addition method (SNA)?
\begin{itemize}
\item Errors from long reads
\item Errors in low complexity regions
\item Difficulty detecting single nucleotide polymorphisms (SNPs)
\item Problems with homopolymers
\end{itemize}

Answer: Problems with homopolymers

\item What is the basis of the Maxam-Gilbert method for DNA sequencing?
\begin{itemize}
\item Amplification of fragments on a solid surface
\item Use of chemicals to break the DNA molecule
\item Adding nucleotides iteratively
\item Electronic detection of pH changes
\end{itemize}

Answer: Use of chemicals to break the DNA molecule

\item What is one of the main advantages of massively parallel sequencing?
\begin{itemize}
\item Generation of long and accurate reads
\item Ability to sequence multiple DNA templates at the same time
\item Capability to perform sequencing at low cost
\item Reduction of error rates in reads
\end{itemize}

Answer: Ability to sequence multiple DNA templates at the same time

\item What technique uses clonal amplification of DNA on solid surfaces?
\begin{itemize}
\item Ion Torrent
\item Pyrosequencing
\item Sequencing by synthesis
\item Nanoballs
\end{itemize}

Answer: Sequencing by synthesis

\item Which sequencing platform is based on proton detection
\begin{itemize}
\item SOLiD
\item Illumina
\item Ion Torrent
\item PacBio
\end{itemize}

Answer: Ion Torrent

\item What was the main technique used in the Human Genome Project?
\begin{itemize}
\item Maxam-Gilbert
\item Pyrosequencing
\item Sanger sequencing
\item Second generation NGS
\end{itemize}

Answer: Sanger sequencing

\item Which NGS platform is known for its low cost per Mb sequenced?
\begin{itemize}
\item Illumina
\item SOLiD
\item 454
\item Ion Torrent
\end{itemize}

Answer: Ion Torrent

\item What is one of the advantages of reversible terminator sequencing technology (CTR)?
\begin{itemize}
\item Does not require clonal amplification
\item Long read length
\item High accuracy in called bases
\item Can handle RNA templates
\end{itemize}

Answer: High accuracy in called bases

\item What NGS technology uses a system of up to two colors for detection?
\begin{itemize}
\item Ion Torrent
\item Illumina
\item PacBio
\item SOLiD
\end{itemize}

Answer: Illumina

\item What are the disadvantages of second generation sequencing systems?
\begin{itemize}
\item Low precision in SNP detection
\item Short read lengths
\item High costs per sequence
\item Low coverage of repetitive regions
\end{itemize}

Answer: Short read lengths

\item What is the main limitation of pyrosequencing?
\begin{itemize}
\item High error rate in low complexity regions
\item Problems with homopolymers
\item High error rate in short segments
\item Difficulty in detecting structural variants
\end{itemize}

Answer: Problems with homopolymers

\item What is one of the main disadvantages of the SOLiD platform?
\begin{itemize}
\item Problems with long reads
\item High error rate in homopolymers
\item Low precision in variation detection
\item Requires an additional cycle for each read
\end{itemize}

Answer: High error rate in homopolymers

\item Which NGS platform is based on luminescence detection?
\begin{itemize}
\item 454
\item Illumina
\item SOLiD
\item Ion Torrent
\end{itemize}

Answer: 454

\item What is a main disadvantage of secong-generation sequencing systems?
\begin{itemize}
\item Low precision in SNP detection
\item Short read lengths
\item High costs per sequence
\item Low coverage of repetitive regions
\end{itemize}

Answer: Short read lengths

\item What key feature defines the Sanger chain termination method?
\begin{itemize}
\item Use of specific enzymes to emit light
\item Use of ddNTPs to stop DNA replication
\item Probe and anchor-based sequencing
\item Use of a microchip with electronic sensors
\end{itemize}

Answer: Use of ddNTPs to stop DNA replication

\item What type of methods are grouped under the term NGS?
\begin{itemize}
\item Massively parallel high-capacity sequencing methods
\item Manual low-precision sequencing methods
\item Methods based on RNA synthesis
\item Methods for detecting three-dimensional structures
\end{itemize}

Answer: Massively parallel high-capacity sequencing methods

\item Which sequencing technique was the first to implement the concept of sequencing by synthesis?
\begin{itemize}
\item Nanoballs
\item SOLiD
\item Sanger
\item 454
\end{itemize}

Answer: Sanger
\end{enumerate}

%04/11 - Álvaro Serrano
\chapter{Alineadores y NGS}
\section{Preparación de librería}
Una librería es una colección de fragmentos de ADN de tamaño aleatorio obtenidos a partir de una muestra que se desea secuenciar. El proceso comienza con la extracción del material genético (ADN o ARN), seguido de su fragmentación en piezas pequeñas que posteriormente serán leídas. A continuación, se añaden adaptadores a los extremos de los fragmentos, lo que permite su hibridación con una fase sólida para realizar la amplificación. Finalmente, se purifican los fragmentos para obtener solo las moléculas del tamaño deseado, dependiendo del método de secuenciación que se vaya a utilizar.

\subsection{Fragmentación del material genético}
Existen distintas técnicas para fragmentar el ADN, cada una con sus ventajas y desventajas:
\begin{itemize}
\item \textbf{Aproximación por ligación:} 
En este método, los fragmentos de ADN se preparan añadiendo una adenina en los extremos, lo que permite la unión complementaria de los adaptadores. Esto produce fragmentos con un adaptador en cada extremo. Cada fragmento tiene así dos componentes: la secuencia del adaptador para la secuenciación y la secuencia molde de ADN. Además, cada fragmento puede llevar un identificador único (UMI, por sus siglas en inglés). 

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/19_ng_lib-prep-frag.png}
\caption{Esquema de la preparación de librerías por fragmentación.}
\end{figure}

Las técnicas de fragmentación por ligación incluyen:
\begin{itemize}
\item \textit{Fragmentación física (sonicación)}:
Mediante un sonicador, se aplican ondas sonoras que generan vibración por resonancia, dividiendo el ADN en fragmentos. La frecuencia de las ondas determina el tamaño de los fragmentos obtenidos.
\item \textit{Fragmentación química:}
Se utilizan agentes químicos, como ácidos o bases fuertes, para romper los enlaces fosfodiéster del ADN. Este método es útil en casos donde la epigenética no es relevante, ya que los químicos fuertes pueden modificar las marcas epigenéticas mediante procesos de oxidación o reducción.
\item \textit{Fragmentación enzimática:}
Se emplean endonucleasas, que son enzimas capaces de cortar las cadenas de ADN en puntos específicos, produciendo fragmentos con extremos cohesivos o romos. Este método permite una fragmentación precisa, pero puede introducir sesgos en la representatividad de la librería generada.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/ligation-methods.png}
\caption{Representación gráfica de los distintos métodos de fragmentación por ligación.}
\end{figure}

\begin{table}[htbp]
\centering
\resizebox{\textwidth}{!}{\begin{tabular}{l | l l l}
& Physical & Chemical & Enzymatic \\ \hline \hline
Pro & Broad range & Well for RNA & Standard lab equipment \\
& Unbiased & & Highly scalable \\
& Less sample variation & Lower input of material \\
& Even sized of fragments & & \\
& No interferences & & \\
& Easy to implement & & \\ \hline
Cons & Expensive equipment & Cations interfere with some seq methods & Fragmentation bias \\
& Loss of material & & Ratio material/enzymes \\
& Modification of bases & & Sample-to-sample variation
\end{tabular}}
\caption{Pros y contras de cada método de fragmentación por ligación}
\end{table}

\item \textbf{Aproximación por tagmentación: }
En este método, se utiliza la enzima tagmentasa, una transposasa que corta la secuencia de ADN e incorpora adaptadores de manera enzimática \footnote{Los transposones son elementos móviles dentro del ADN.}. La tagmentación es rápida y eficiente, pues combina la fragmentación y la adición de adaptadores en un solo paso.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/tagmentation.png}
\caption{Representación esquemática de la fragmentación por tagmentación.}
\end{figure}
\end{itemize} 

\subsection{Reparación de extremos y ligación de adaptadores}
Después de la fragmentación del ADN, es necesario reparar los extremos de los fragmentos. Como la fragmentación no suele producir cortes limpios, los fragmentos generados suelen presentar extremos sobresalientes (overhangs). Para corregir esto, se realiza un tratamiento enzimático con polimerasas, que además añade una adenina (A) en los extremos 3’. Estos extremos, con la adenina añadida, facilitan la ligación de los adaptadores, los cuales suelen tener un overhang de timina (T) para permitir una unión complementaria con los fragmentos de ADN.

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/adaptator.png}
\caption{Representación de los adaptadores en caso de secuenciación simple, dual y UDI-UMI.}
\end{figure}

Los adaptadores empleados en la secuenciación tienen distintas configuraciones. Por lo general, se colocan dos tipos de adaptadores: el adaptador P5 en un extremo y el adaptador P7 en el otro. Esta disposición permite identificar las direcciones de lectura durante el proceso de secuenciación. Además, algunos adaptadores incluyen identificadores moleculares únicos, conocidos como UMIs (Unique Molecular Identifiers), que permiten rastrear de forma única cada molécula de ADN. Durante la amplificación, todas las moléculas con el mismo UMI corresponden a la misma molécula de ADN original. Esto tiene múltiples beneficios:
\begin{itemize}
\item \textbf{Eliminación de duplicados de PCR:} Permite distinguir duplicados generados por PCR de secuencias originales.
\item \textbf{Disminuir el ratio de error:} La lectura de la misma molécula varias veces permite detectar posibles errores generados durante la construcción de la librería o la amplificación. Si diferentes secuencias presentan un UMI idéntico pero difieren en algún nucleótido, se puede deducir que ha habido un error, ya que las secuencias deberían ser idénticas. Esto ayuda a reducir el índice de error y a detectar variantes poco frecuentes.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/umi-variants.png}
\caption{Representación de variantes con y sin UMIs.}
\end{figure}

En el método conocido como \textbf{Duplex Sequencing}, se emplean UMIs distintos en ambos extremos del fragmento de ADN. De este modo, durante el análisis de consenso, se pueden identificar las posiciones que muestran concordancia entre ambas hebras y descartar los nucleótidos mutados por error.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/duplex-sequencing.jpg}
\caption{Visión general de la secuenciación dúplex. (a) Esquema de un adaptador de secuenciación dúplex, que muestra la etiqueta aleatoria de doble cadena y la secuencia espaciadora invariante. (b) La ligación de los adaptadores con el ADN de la muestra da lugar a una secuencia única de 12 nt en ambos extremos de la molécula. La amplificación por PCR de cada cadena de un dúplex de ADN da lugar a dos productos de PCR distintos pero relacionados. (c) Las lecturas que comparten secuencias únicas de etiquetas $\alpha$ y $\beta$ se agrupan en familias de etiquetas de forma $\alpha \beta$ o $\beta \alpha$, y se crea un SSCS (single-strand consensus sequence) para cada familia de etiquetas. Las mutaciones son de tres tipos diferentes: errores de secuenciación (puntos azules o morados); errores de PCR de primera ronda (puntos marrones); mutaciones verdaderas (puntos verdes). La formación del SSCS elimina el primer tipo de error, pero no los errores de PCR de la primera ronda. La comparación de los SSCS de las familias emparejadas con etiquetas $\alpha \beta$ y $\beta \alpha$, genera un DCS (duplex consensus sequence), que elimina estos errores de PCR de primera ronda. Las mutaciones verdaderas se puntúan si y sólo si están presentes en la misma posición en ambas cadenas del ADN. "Detecting ultralow-frequency mutations by Duplex Sequencing, Nature, 2014"}
\end{figure}

Aunque los métodos basados en UMIs son altamente eficaces para detectar variantes de muy baja frecuencia, su uso es limitado debido a su alto costo, ya que requieren múltiples lecturas de la misma secuencia para asegurar precisión.

\subsection{Adaptadores para secuenciación de célula única (single cell)}
En la secuenciación de célula única (Single Cell), se emplean adaptadores y primers que contienen UMIs específicos tanto para cada célula como para cada molécula de ADN. Esto permite diferenciar si las lecturas corresponden a una célula particular y, dentro de esa célula, a una molécula específica. En Single Cell, se utiliza un enfoque de consenso: las lecturas múltiples de la misma molécula permiten generar una secuencia de consenso para mejorar la precisión de los datos.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/single-cell-seq.jpg}
\caption{Descripción esquemática de la generación de GEM (gel beads-in-emulsions) y el código de barras con el flujo de trabajo del chip GEM-X. Los GEM se generan combinando perlas de gel con código de barras, una mezcla maestra que contiene células y aceite de partición en un chip GEM-X 3' o 5'. Para lograr una resolución unicelular, las células se suministran a una dilución límite, de modo que la mayoría ($\approx$90-99\%) de los GEM generados no contienen ninguna célula, mientras que el resto contiene en gran medida una sola célula.}
\end{figure}

La construcción de librerías en Single Cell se realiza mediante chips que permiten el paso de flujo de células individuales junto con liposomas que contienen la mezcla de PCR. Cada mezcla de PCR tiene adaptadores con un barcode específico de célula, pero diferentes barcodes de molécula. Esto permite identificar y diferenciar las células individuales entre sí.

%Glosario
\begin{table}[htbp]
\begin{mdframed}[backgroundcolor=black!10]
    \centering
\textbf{Glosario}
\begin{description}
\item[Adaptadores:] Moléculas cortas de ADN fabricadas artificialmente que se unen a fragmentos de ADN y se utilizan para unirse a la célula de flujo.
\item[Barcoding:] El proceso de identificar muestras de ADN añadiendo índices a los fragmentos de ADN durante la preparación de la librería.
\item[Índice:] Molécula corta de ADN fabricada artificialmente que se utiliza para asignar códigos únicos a las muestras, lo que permite su identificación durante la secuenciación.
\item[Insert:] Fragmento de ADN entre dos adaptadores.
\item[Librería:] Una colección de fragmentos de ADN de tamaño aleatorio procedentes de una muestra determinada para ser secuenciados.
\item[Preparación de librería por ligación:] Método para ligar adaptadores a fragmentos de ADN para ser secuenciados.
\item[Multiplexing:] El proceso de añadir índices a los fragmentos de ADN durante la preparación de la librería.
\item[Oligos:] Moléculas de ADN artificial unidas a la célula de flujo que se unen por complementación a los adaptadores de los fragmentos de ADN.
\item[Lecturas/Reads:] Secuencias de pares de bases obtenidas de fragmentos de ADN.
\item[Preparación de librería por tagmentación:] Método para cortar y ligar adaptadores a fragmentos de ADN utilizando una enzima transposasa.
\item[Transposasa:] Enzima utilizada en la preparación de bibliotecas de marcaje para cortar y ligar adaptadores a fragmentos de ADN.
\end{description}
    \end{mdframed}
\end{table}

\section{Formatos de datos}
El formato de archivo usado por los alineadores es generalmente \textbf{FastQ} para las secuencias, aunque \textbf{Fast5} o \textbf{HDF5} también se emplean en algunos casos, especialmente en secuenciación de célula única (single cell), donde se necesita un mayor nivel de detalle en el almacenamiento de datos.

Cuando se trabaja con alineadores, el proceso suele generar un perfil con picos que representan las bases detectadas, a cada uno de los cuales se le asigna un nombre de base. El alineador produce un archivo final que contiene tanto la secuencia de bases asignadas como la calidad de lectura de cada base en un formato codificado llamado \textbf{Phred33}, que usa caracteres ASCII para representar los valores de calidad.

En formatos antiguos, la cabecera de cada secuencia incluía datos detallados, como el nombre del instrumento de secuenciación, el identificador del flowcell, las coordenadas X e Y del clúster, el número de la muestra y el índice del par de lectura. En el formato actual, esta información en la cabecera ha sido simplificada o se presenta de manera distinta.

En cuanto al tipo de secuenciación, se distinguen dos tipos:
\begin{itemize}
\item \textbf{Single-end:} lee la secuencia en una sola dirección.
\item \textbf{Paired-end:} realiza lecturas en ambas direcciones, proporcionando información desde ambos extremos del fragmento de ADN. La secuenciación puede ser solapante (overlapping) para incrementar la evidencia de la secuencia, o no solapante (non-overlapping) cuando se busca mapear estructuras más amplias sin redundancia en los extremos.
\end{itemize}

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/singleEndVsPairedEnd.png}
\caption{Representación gráfica de la diferencia entre Single end y Paired end.}
\end{figure}

Durante un experimento de secuenciación, se utiliza un programa llamado \textbf{FastQC} para evaluar la calidad de las bases a lo largo de la lectura mediante una métrica llamada \textbf{Q score}. La visualización de estos resultados suele hacerse a través de diagramas de barras y cajas. Normalmente, la calidad de las bases tiende a disminuir conforme avanzan los ciclos de lectura, pero debe mantenerse dentro de un rango confiable.

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/good-bad-fastq.png}
\caption{La calidad de la secuencia por base, que representa la puntuación Q de la secuencia en crudo, se lee como un gráfico de caja para cada ciclo. Cuanto más alto, mejor, y en la mayoría de los ciclos se observa un descenso característico de la calidad.}
\end{figure}

FastQC proporciona varias métricas clave para evaluar la calidad: 
\begin{itemize} 
\item \textbf{Calidad promedio de la secuencia}: muestra la calidad media de las bases en cada posición. 
\item \textbf{Proporciones de bases por posición}: indica la proporción de bases (A, T, C, G) en cada posición. 
\item \textbf{Contenido de bases por posición}: permite identificar cualquier sesgo en el contenido de bases a lo largo de la secuencia. 
\item \textbf{Contenido GC:} al inicio de la secuenciación, puede haber una variación en el contenido GC debido a la secuencia de los adaptadores, pero si se estabiliza después de las primeras bases, indica una secuenciación correcta y se pueden cortar los primeros nucleótidos. 
\end{itemize}

\section{Preprocesamiento y genomas de referencia} 
El preprocesamiento de las lecturas aumenta la calidad de las secuencias, mejora el mapeo, elimina posibles contaminantes y sesgos, y descarta segmentos no informativos.

Las secuencias generadas se comparan con \textbf{genomas de referencia}, que generalmente están en formato \textbf{FASTA}. En estos archivos, los nucleótidos están representados según el código IUPAC para permitir una representación estándar de variaciones. Históricamente, los genomas de referencia se creaban con la información genética de un solo individuo. Sin embargo, hoy en día, se basan en el consenso de los genomas de múltiples individuos, lo que permite identificar variantes y posiciones con alta confianza que difieren entre individuos.

Los genomas de referencia y sus anotaciones se pueden encontrar en sitios como \href{https://hgdownload.soe.ucsc.edu/downloads.html}{UCSC Genome Browser}. Es importante tener en cuenta las diferencias en las anotaciones genómicas entre repositorios europeos y americanos, ya que pueden variar en la numeración y anotación de los cromosomas.

\section{Alineamientos y mapeo}
El alineamiento es el proceso de comparar secuencias de ADN, ARN o proteínas para identificar regiones de similitud, lo cual puede revelar relaciones funcionales, estructurales o evolutivas entre especies. Los objetivos principales del alineamiento son:
\begin{itemize}
\item Determinar el grado de homología para inferir relaciones filogenéticas
\item Identificar dominios funcionales
\item Comparar el gen con sus productos asociados
\item Encontrar posiciones homólogas entre secuencias
\item Identificar diferencias entre secuencias similares
\end{itemize}

\subsection{Alineamiento vs Mapeo}
Aunque a menudo se usan indistintamente, el alineamiento y el mapeo tienen diferencias importantes:
\begin{itemize}
\item \textbf{Alineamiento:} Cada posición de la secuencia de consulta se compara exhaustivamente con una secuencia de referencia para evaluar su precisión en cada sitio.
\item \textbf{Mapeo:} El objetivo es encontrar los loci más probables en la referencia donde una secuencia podría alinearse, priorizando eficiencia en velocidad y memoria.
\end{itemize}

Existen programas diseñados específicamente para el mapeo, llamados alineadores de corta lectura, que permiten configuraciones de mapeo como mapeo único, mapeo múltiple o mapeo con calidades parciales. Dependiendo del tipo de secuenciación, se emplean diferentes alineadores:
\begin{itemize}
\item \textbf{Para ADN:} Novoalign, Bowtie2, BWA
\item \textbf{Para ARN:} RSEM, Salmon, Sleuth
\end{itemize}

\subsection{Algoritmos de mapeo por hashing}
El mapeo inicia con una etapa de \textbf{indexación del genoma}, un proceso intensivo en tiempo y memoria que se realiza solo una vez por genoma de referencia y por programa. En esta fase, los algoritmos de alineamiento utilizan técnicas como \textbf{hashing} o \textbf{índices} basados en \textbf{k-mers} (subsecuencias de longitud fija). Con una ventana móvil, se anotan las posiciones de cada k-mer en la secuencia de referencia.

Posteriormente, las lecturas se comparan con el diccionario de k-mers para localizar sus posiciones sin usar una ventana móvil adicional. A continuación, se construye un "árbol de posibilidades" que evalúa la compatibilidad de cada lectura con la referencia. Si una mutación en la lectura no coincide con la referencia, el k-mer no estará en el índice, y se buscarán los k-mers más cercanos, evaluando el mapping quality según el número de errores (mismatches) y la distancia de edición. El objetivo es minimizar los gaps (espacios sin coincidencias) para mejorar la precisión del alineamiento.

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/hash-mapping.png}
\caption{Mapeado basados en hash o índices. El primer paso es obtener el hash o índice del genoma de referencia completo. A continuación, se utilizan esos índices para mapear (es decir, encontrar sitios de alineamiento) las lecturas.}
\end{figure}

\subsection{Transformación de Burrows-Wheeler (BWT)}
La \textbf{transformación de Burrows-Wheeler} es un método de compresión que permite realizar búsquedas rápidas de alineamiento en el genoma de referencia, optimizando el rendimiento de los alineadores.

\subsection{Estados de lecturas post-mapeo y mapping quality}
Una vez mapeadas las lecturas al genoma de referencia, estas pueden clasificarse en distintos estados:
\begin{itemize}
\item \textbf{Lecturas no mapeadas:} No encuentran ninguna coincidencia en la referencia.
\item \textbf{Lecturas con mapeo único:} Mapean en una sola posición. Normalmente se trabaja con estas lecturas.
\item \textbf{Lecturas con mapeo múltiple (multimappers):} Mapean en varias posiciones. Se distinguen primarios y secundarios en función de la puntuación de mapeo.
\end{itemize}

Existen opciones para reportar todos los alineamientos, solo los mejores, o aquellos que superan un umbral de calidad específico.

La calidad de mapeo usa la misma escala Phred33 que las calidades de lectura, y los resultados de alineación se almacenan en formatos SAM, BAM o CRAM:
\begin{itemize}
\item \textbf{SAM:} Formato de texto plano que se puede leer por la terminar.
\item \textbf{BAM:} Versión binaria de SAM.
\item \textbf{CRAM:} Similar a BAM, pero usado principalmente por el EBI, optimizado para almacenar una cantidad masiva de datos de forma compacta.
\end{itemize}

Los formatos SAM y BAM se pueden convertir entre sí mediante la herramienta \textbf{samtools}, que permite especificar el grado de compresión.

La cabecera del archivo S/BAM comienza con \@ y almacena metadatos como la versión de SAM, la ordenación, los contigs y la información general del mapeo. 
\begin{figure}
\centering
\includegraphics[width = \textwidth]{figs/sam-header.png}
\caption{Campos que incluye la cabecera de los ficheros SAM y BAM.}
\end{figure}

Los datos de alineación incluyen: 
\begin{itemize} 
\item Nombre de la lectura 
\item Flag: Indica si la lectura está mapeada o no, entre otras propiedades. Sigue la codificación de \href{https://broadinstitute.github.io/picard/explain-flags.html}{picard}.
\item Cromosoma: Donde se ha mapeado la lectura. 
\item Posición inicial en el cromosoma 
\item Calidad de mapeo 
\item CIGAR string: Codificación de los eventos de alineamiento (match, mismatch, inserciones, deleciones). Por ejemplo, un CIGAR de 3M1D2M1I1M indica que hay 3 match, 1 deleción, 2 match, 1 inserción y 1 match.
\item Información sobre el mapeo del par: En caso de secuenciación paired-end, se incluye la ubicación de la pareja de la lectura. 
\end{itemize}

%06/11 - Álvaro Serrano
\subsection{Otros formatos de ficheros en bioinformática}
\paragraph{Bed para intervalos}
Este formato da información de coordenadas. Tiene 3 columnas obligatorias: cromosoma, posición de inicio (0 based) y posición de fin (1 based). Estas posiciones se pueden restar para obtener el tamaño del fragmento. Bed es un formato abierto que puede incluir otras columnas: nombre, score, strand, etc. Estos ficheros son de texto plano, aunque tienen la extensión .bed. 

\paragraph{VCF para llamada de variantes}
Las variantes son posiciones en el genoma que se marcan como mutadas. Tiene una cabecera que empieza con una doble almohadilla. Es un fichero de texto plano, que se puede binarizar en un fichero bcf. Dentro del cuerpo, las columnas son cromosoma, posición de la mutación, ID, nucleótido en la referencia, alternativa (nucleótido observado en la mutación), calidad (profundidad a la que se ha secuenciado, es decir, veces que se ha secuenciado una determinada posición), filtro , información adicional, tipo de formato y muestras. También aporta información sobre la fase, es decir, si una misma lectura detecta varias mutaciones.

\paragraph{GTF y GFF para transcriptomas de referencia} 
Estos archivos contienen anotaciones de elementos (secuencia codificante, non-coding RNA, etc) referidos al genoma, por lo que es útil para experimentos de transcriptómica. Cada característica está en una fila con nueve columnas separadas por tabuladores: nombre de la secuencia, fuente, característica, posición de inicio y de fin (ambas basadas en 1), score, strand, frame y atributos. 

\paragraph{CSV y TSV para cuentas}
No hay especificaciones de formato, ni límites en cuanto a la dimensión de la matriz. Son ficheros tabulares estándares. Es importante tener buenas prácticas, es decir, utilizar nombres intuitivos para columnas y filas, y no utilizar espacios, si no puntos o barras bajas. En las filas se guardan las observaciones, y las columnas las características. 

\chapter{Secuenciación de tercera generación}
La secuenciación de segunda generación, como los métodos basados en Illumina, permite obtener lecturas pequeñas (de alrededor de 100-300 pb) y de alta precisión, pero presenta limitaciones al enfrentar regiones genómicas complejas, como las altamente repetitivas, debido a la longitud de las lecturas. La secuenciación de tercera generación surge para superar estas limitaciones, proporcionando lecturas más largas (de varias kilobases) que permiten el análisis detallado de variantes estructurales, lo cual es esencial para estudios de genómica estructural y ensamblaje de genomas complejos.

Se distinguen dos enfoques principales en la secuenciación de tercera generación:
\begin{itemize}
\item \textbf{Secuenciación de molécula única:} secuencia cada molécula individual sin amplificación clonal, reduciendo así el sesgo introducido por técnicas de PCR. Destacan PacBio y Oxford Nanopore, cada uno con sus características particulares en cuanto a precisión, velocidad y métodos de detección.
\item \textbf{Aproximaciones sintéticas (basadas en Illumina):} permiten reconstruir secuencias largas a partir de lecturas cortas mediante ensamblaje. Estas no se consideran tercera generación en sentido estricto, pero comparten ciertos objetivos en cuanto a mejorar la resolución de lecturas largas (se habla de pseudotercera generación).
\end{itemize}

\section{Secuenciación de molécula única a tiempo real - PacBio}
La tecnología de PacBio (Pacific Biosciences) emplea una única molécula de ADN de longitud variable, generalmente en el rango de varias kilobases. Se preparan fragmentos circulares de ADN al añadir estructuras químicas en forma de horquilla en los extremos, lo que permite la circularización de la molécula y una lectura continua de la secuencia.

El secuenciador PacBio utiliza un flowcell con pocillos que contienen cámaras donde se detectan señales de fluorescencia para identificar los nucleótidos incorporados en tiempo real. Este proceso funciona gracias a una polimerasa anclada en cada pocillo que, al añadir nucleótidos marcados con fluorescencia, permite que la cámara capture el cambio y lea la secuencia. La velocidad de secuenciación es de aproximadamente 3 bases por segundo.

Cada pocillo secuencia una molécula única no amplificada que proviene directamente del organismo a estudiar. Al estar la molécula circularizada, la secuenciación puede realizarse de manera continua: la polimerasa desnaturaliza la cadena, incorpora nucleótidos y la cadena sintetizada se deshibrida, permitiendo múltiples pasadas sobre la misma región.

\begin{figure}[htbp]
\centering
\includegraphics[width = \textwidth]{figs/pacbio.png}
\caption{La plataforma de secuenciación PacBio es una plataforma de secuenciación de lectura larga, también conocida como una de las tecnologías de secuenciación de tercera generación (TGS). La tecnología central, la molécula única en tiempo real (SMRT), permite generar lecturas de decenas de kilobases de longitud. Sobre la base de la «secuenciación por síntesis», la resolución de nucleótidos individuales se consigue mediante la guía de ondas de modo cero (ZMW), en la que sólo se ilumina un volumen limitado en la parte inferior (el lugar de síntesis de la molécula). Además, la secuenciación SMRT evita en gran medida el sesgo de secuencia específica en el sistema NGS, ya que la mayoría de los pasos de amplificación PCR no son necesarios en el proceso de construcción de bibliotecas.}
\end{figure}

PacBio permite dos enfoques distintos:
\begin{itemize}
\item \textbf{Circular Long Templates (CLT):} se secuencian fragmentos largos una sola vez para capturar grandes porciones de información estructural del ADN.
\item \textbf{Circular Consensus Sequencing (CCS):} se secuencian fragmentos más cortos repetidamente, lo que permite asegurar la precisión en cada posición al promediar múltiples lecturas del mismo fragmento.
\end{itemize}

Este método es especialmente útil en el ensamblaje de genomas debido a la longitud de las lecturas. La calidad en el modo CCS puede alcanzar valores elevados (Q50), aunque en regiones de homopolímeros extensos puede haber dificultades en la discriminación precisa de nucleótidos individuales, generando posibles discrepancias con la secuencia real si solo se realiza una pasada.
%PacBio Sequencing - How it works YouTube

\section{Secuenciación por Nanoporos - Oxford Nanopore Technology (ONT)}
La tecnología de secuenciación por nanoporos, desarrollada por Oxford Nanopore, utiliza proteínas alfa-hemolisinas que forman poros a través de los cuales pasa una cadena de ADN, generando una señal eléctrica que permite identificar los nucleótidos en tiempo real. Esta señal, medida como una interferencia de corriente (diferencia de potencial), permite la identificación directa de bases sin la necesidad de etiquetas de fluorescencia, lo cual distingue a ONT de otros métodos de secuenciación.

En el caso de ADN de doble cadena, el sistema emplea una proteína motora que desnaturaliza el ADN, permitiendo que solo una cadena pase a través del poro. A medida que cada nucleótido atraviesa el poro, la interferencia generada, conocida como \textbf{"squiggle" o garabato}, se mide y se asocia con una secuencia de bases. Para traducir esta señal en una secuencia, se comparan patrones de squiggles generados experimentalmente con secuencias sintéticas (o "similares"), lo que permite identificar los nucleótidos en cada posición.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.8\textwidth]{figs/nanopore.png}
\caption{Una celda de flujo MinION contiene 512 canales con 4 nanoporos en cada canal, para un total de 2.048 nanoporos utilizados para secuenciar ADN o ARN. Los pocillos se insertan en una membrana de polímero resistente a la electricidad soportada por una matriz de microesqueletos conectados a un chip sensor. Cada canal se asocia a un electrodo independiente en el chip sensor y es controlado y medido individualmente por el circuito de integración de aplicaciones específicas (ASIC). La corriente iónica pasa a través del nanoporo porque se aplica un voltaje constante a través de la membrana, donde el lado trans está cargado positivamente. Bajo el control de una proteína motora, primero se desenrolla una molécula de ADN de doble cadena (o un dúplex híbrido de ARN-ADN) y, a continuación, el ADN o ARN monocatenario con carga negativa se desplaza a través del nanoporo, impulsado por el voltaje. A medida que los nucleótidos atraviesan el nanoporo, se mide un cambio de corriente característico que se utiliza para determinar el tipo de nucleótido correspondiente a unas 450 bases por s. "Nanopore sequencing technology, bioinformatics and applications, Nature, 2021"}
\end{figure}

El sistema ONT incluye una región denominada \textbf{k-mero} en el poro, que es el área de mayor estrechamiento y donde la señal de corriente es más intensa. Esto permite capturar mayor información y mejorar la precisión de la secuenciación, aunque este proceso es complejo y requiere el uso de algoritmos avanzados, como redes neuronales, para categorizar las señales y asignar los nucleótidos correspondientes.

La tecnología de ONT es altamente precisa y tiene la capacidad de secuenciar hasta 500 megabases, con un tamaño promedio de lectura de entre 4-6 kilobases. Sin embargo, la calidad de las lecturas puede ser inferior a otros métodos de secuenciación, con una precisión de aproximadamente 92-93\%, debido en parte a las limitaciones en la resolución de homopolímeros y otras regiones repetitivas.

A pesar de estas limitaciones, la tecnología ONT es portátil, escalable y rápida, lo que permite lecturas largas sin necesidad de amplificación por PCR. La tecnología admite modificaciones químicas en el ADN, como la adición de un "hairpin" (estructura en horquilla), que permite secuenciar ambas hebras del ADN en un solo paso.

Las principales desventajas de la secuenciación por nanoporos son la elevada tasa de error y las dificultades en regiones con homopolímeros extensos, así como su dependencia de "training sets" (conjuntos de datos de entrenamiento) actualizados para mejorar la precisión en el análisis de secuencias complejas.

\section{Consideraciones generales sobre la secuenciación de tercera generación}
Las técnicas de secuenciación de tercera generación han revolucionado el campo de la genómica estructural, permitiendo lecturas largas que facilitan el ensamblaje de genomas completos y el análisis de variaciones estructurales. Sin embargo, en comparación con la secuenciación de segunda generación, presentan una menor precisión en general. A medida que se integran algoritmos de inteligencia artificial y técnicas avanzadas de procesamiento de señales, la precisión de estas tecnologías sigue mejorando.

Un desafío específico en estas tecnologías es la susceptibilidad de las moléculas únicas a la adición de múltiples nucleótidos, lo que puede generar errores en homopolímeros y regiones complejas del ADN.

\section{Resumen}
La secuenciación de tercera generación permite secuenciar templates más largos, siendo así mejor para variantes estructurales. Además, no es necesaria la amplificación clonal. En \textbf{PacBio}, se utilizan templates circularizados. La polimerasa incorpora dNTPs con fluoróforos que se capturan por una cámara directamente cuando se unen. Es muy rápido (3 bases por segundo), pero sufre en regiones con homopolímeros. Se secuencian los templates largos una vez con una tasa de error alta o templates cortos varias veces para obtener el consenso. En \textbf{Nanopore}, se comprueba directamente la composición de un ssDNA mediante la interpretación de la interrupción de la corriente (el garabato o squiggle). Dentro del poro, la zona estrecha dtermina el k-mero. Éste sufre más con homopolímeros cuando el k-mero es más corto. Tiene una tasa de error alta, pero se está optimizando con machine learning. También puede haber problemas con bases modificadas. Los equipos son muy portables, lo que supone una gran ventaja.

\section{Quizz}
\begin{enumerate}
\item What is an advantage of hash table-based mapping?
\begin{itemize}
\item Allows alignment without reference
\item Requires less memory
\item Higher speed and efficiency
\item Only used with long reference genomes
\end{itemize}

Answer: Higher speed and efficiency

\item What does the variant allele frequency (VAF) mean?
\begin{itemize}
\item The number of observed reads that match a specific variant
\item The percentage of errors in a sequence
\item The number of sequences in a reference genome
\item The quality of the sequence in an alignment
\end{itemize}

Answer: The number of observed reads that match a specific variant

\item What does a high Phred Q value in quality scores mean?
\begin{itemize}
\item Higher probability of error
\item Higher accuracy in the called base
\item Low quality sequences
\item Systematic error in final bases
\end{itemize}

Answer: Hiher accuracy in the called base

\item What is an example of a short read aligner (SRA)?
\begin{itemize}
\item ClustalW
\item BWA
\item Excel
\item SnapGene
\end{itemize}

Answer: BWA

\item What does 'NGS' mean?
\begin{itemize}
\item Next Genomic Study
\item Next Generation Sequencing
\item Next Generation Science
\item Next Generation Studies
\end{itemize}

Answer: Next Generation Sequencing

\item What file format is used to represent DNA sequences with their quality scores?
\begin{itemize}
\item VCF
\item SAM
\item FASTQ
\item GFF
\end{itemize}

Answer: FASTQ

\item What does a GTF/GFF file describe in bioinformatics?
\begin{itemize}
\item DNA mutations
\item Genomic annotations
\item Sequence variants
\item Reference sequences
\end{itemize}

Answer: Genomic annotations

\item What is the goal of unique molecular identifiers (UMI)?
\begin{itemize}
\item Identify individual molecules and reduce PCR duplicates
\item Align reference DNA
\item Improve the VCF file format
\item Store alignment quality
\end{itemize}

Answer: Identify individual molecules and reduce PCR duplicates

\item What type of file is used to represent genomic coordinates in interval analysis?
\begin{itemize}
\item FASTA
\item BAM
\item BED
\item CRAM
\end{itemize}

Answer: BED

\item What type of format is commonly used to store the reference genome?
\begin{itemize}
\item FASTA
\item BED
\item BAM
\item SAM
\end{itemize}

Answer: FASTA

\item What do UMIs represent in sequencing?
\begin{itemize}
\item Duplication indicators
\item Unique molecular identifiers
\item Adapter sequences
\item Alignment marks
\end{itemize}

Answer: Unique molecular identifiers

\item What is the main purpose of a library in sample preparation?
\begin{itemize}
\item Store sequence data
\item Fragment DNA
\item Generate DNA fragments from a sample for sequencing
\item Calculate the quality of the sequence
\end{itemize}

Answer: Generate DNA fragments from a sample for sequencing

\item What component in a VCF file indicates the score assigned to a variant call?
\begin{itemize}
\item Chr
\item Qual
\item Pos
\item Alt
\end{itemize}

Answer: Qual

\item What is the BED format used for in bioinformatics?
\begin{itemize}
\item Store alignments
\item Represent genomic coordinates
\item Sequence DNA
\item Store quality data
\end{itemize}

Answer: Represent genomic coordinates

\item What file format is used to report genetic variations?
\begin{itemize}
\item SAM
\item FASTA
\item GTF
\item VCF
\end{itemize}

Answer: VCF

\item What is the Phred Q value if the probability of error is 1 in 100?
\begin{itemize}
\item 10
\item 20
\item 30
\item 40
\end{itemize}

Answer: 20

\item What technology uses real-time single-molecule sequencing?
\begin{itemize}
\item Illumina
\item PacBio
\item SOLiD
\item ABI
\end{itemize}

Answer: PacBio

\item What is the CIGAR line in a SAM/BAM file?
\begin{itemize}
\item An ASCII code line
\item A compressed representation of an alignment
\item The identification of the reference sequence
\item A metadata line
\end{itemize}

Answer: A compressed representation of an alignment

\item Which of the following is a characteristic of BAM files?
\begin{itemize}
\item They are human-readable text files
\item They are binary alingment files
\item They cannot be compressed
\item They are reference genome files
\end{itemize}

Answer: They are binary alignment files

\item What is the function of adapters in NGS?
\begin{itemize}
\item Sequence RNA fragments
\item Ligate DNA fragments to flow cells
\item Fragment DNA
\item Adjust the quality of the sequence
\end{itemize}

Answer: Ligate DNA fragments to flow cells

\item What is one of the mandatory columns in a VCF file?
\begin{itemize}
\item Qual
\item ID
\item REF
\item All of the above
\end{itemize}

Answer: All of the above

\item Which of the following options is NOT a stage in library preparation?
\begin{itemize}
\item Fragmentation
\item Ligate adapters
\item Mapping analysis
\item Purification
\end{itemize}

Answer: Mapping analysis

\item What file is a human-readable text format that contains sequence alignment information?
\begin{itemize}
\item SAM
\item BAM
\end{itemize}

Answer: SAM

\item What file is a human-readable text format that contains sequence alignment information?
\begin{itemize}
\item SAM
\item BAM
\item VCF
\item GFF
\end{itemize}

Answer: SAM

\item What is the main feature of nanopore sequencing?
\begin{itemize}
\item Ionic current monitoring to detect DNA composition
\item Use of fluorescent tags on each base
\item Low throughput
\item Only sequence RNA
\end{itemize}

Answer: Ionic current monitoring to detect DNA composition

\item What type of alignment is characteristic of NGS?
\begin{itemize}
\item Alignment based on long sequences
\item Short read alignment to a reference genome
\item Alignment with very low quality sequences
\item Alignment without the need for reference
\end{itemize}

Answer: Short read alignment to a reference genome

\item What library preparation method uses the transposase enzyme?
\begin{itemize}
\item Ligate adapters directly
\item Ligate UMIs
\item Tagmentation
\item Generate high-quality sequences
\end{itemize}

Answer: Tagmentation

\item What file is the binary version of a SAM file?
\begin{itemize}
\item CRAM
\item BAM
\item FASTA
\item CSV
\end{itemize}

Answer: BAM

\item What file is typically used to store tabular data in bioinformatics?
\begin{itemize}
\item CSV/TSV
\item BED
\item FASTA
\item CRAM
\end{itemize}

Answer: CSV/TSV

\item What is the main advantage of third-generation sequencing?
\begin{itemize}
\item Low accuracy
\item Long reads without template amplification
\item High speed without alignment
\item Low error rate in homopolymeric regions
\end{itemize}

Answer: Long reads without template amplification
\end{enumerate}

%aserrano@cnic.es
%08/11 - Tomás di Domenico
\chapter{Whole Genome Sequencing (WGS)}
\section{Introducción a Whole Genome Sequencing}
WGS implica secuenciar todo el genoma de telómero a telómero. Esto se debe a que antes no se solía secuenciar todo el genoma, si no algún panel o el exoma. Ahora, el genoma completo sí se está secuenciando por la disminución de los costes. 
\begin{itemize}
\item \textbf{Targeted panel sequencing}: como se selecciona un fragmento a secuenciar, se consigue una mayor cobertura por el mismo precio.
\item \textbf{Whole-exome sequencing (WES):} se secuencia todo el exoma, por lo que la cobertura es intermedia.
\item \textbf{Whole-genome sequencing (WGS):} se secuencia todo el genoma, pero con una cobertura menor.
\end{itemize}

Las ventajas de WGS es que no hay ADN "basura", y que mucha regulación ocurre en el genoma no codificante. Además, las variantes estructurales solo se ven con una perspectiva completa. En resumen, un WGS es la representación completa del genoma de un organismo. No obstante, no siempre se realiza WGS por temas económicos: los costes de secuenciación, los costes de almacenamiento y los costes de análisis. El exoma representa un 1\% del genoma, por lo que conseguir una mayor cobertura en WES es más barato que en WGS.

\begin{figure}[htbp]
\centering
\includegraphics[width = 0.7\textwidth]{figs/wge-wgs.png}
\caption{Comparación de las coberturas recomendadas para WGE y WGS en base a su aplicación.}
\end{figure}

WGS tiene tres aplicaciones fundamentales:
\begin{itemize}
\item \textbf{Ensamblajes:} El ensamblaje de un genoma es una de las principales ventajas de poder secuenciar un genoma completo. Los ensamblajes basados en NGS implican reconstruir secuencias desde lecturas cortas, lo que es muy exigente computacionalmente. De las lecturas se forman los contigs, los cuales se ensamblan en scaffolds. Finalmente, los scaffolds se pueden ensamblar en pseudocromosomas y cromosomas. La generación de un genoma completo, pese a seguir siendo caro, ha reducido su coste desde el Proyecto Genoma Humano. Es importante poder hacer un ensamblado porque el genoma de referencia no es representativo por la diversidad natural y en algunos casos tiene muchos huecos.
\item \textbf{Genome-wide Association Studies (GWAS):} El análisis de variaciones a nivel genómico se puede realizar mediante la seuenciación de datos genómicos. No obstante, sigue habiendo problemas en cuanto a la relevancia y la estadística).
\item \textbf{Análisis de variantes estructurales:} La variación estructural, o la reorganización de partes del genoma de varias formas solo es posible capturarla mediante la secuenciación del genoma completo.
\end{itemize}

La principal limitación de NGS es que generan lecturas muy cortas, además de tener limitaciones intrínsecas por los métodos químicos que se utilizan a la hora de secuenciar. De estos métodos, el más popular es el de la secuenciación por síntesis, que es el que implementa Illumina en su secuenciación. Después de varias rondas de extensión y escaneado, las copias de la secuencia en un cluster empieza a descoordinarse, por lo que hay una limitación del tamaño de las lecturas. Esto es particularmente exigente cuando se trata de regiones que pueden estar repetidas a lo largo del genoma, ya que los ensamblajes pueden mostrar sesgos, dando lugar a huecos en los ensamblajes de referencia. Los genomas suelen ser muy repetitivos, pero hay distintos grados de repetitividad (simple y complejo). Así, no toda la parte repetitiva impide el ensamblaje, pero causa estragos.

\section{Práctica - lecturas cortas}
Ahora vamos a adquirir experiencia práctica con un ensamblaje de lecturas cortas y su análisis.
Como no tenemos tiempo ni recursos para trabajar con un genoma entero, trabajaremos con un fragmento amplificado por BAC del cromosoma 3 humano.
Utilizaremos ABySS para ensamblar un cromosoma artificial bacteriano (BAC) de 200 kbp utilizando un carril de lecturas paired-end de la plataforma Illumina. BWA-MEM se utiliza para alinear los contigs ensamblados con el genoma humano de referencia. IGV se utiliza para visualizar estas alineaciones y variantes.
Después de esta práctica, habremos aprendido a ensamblar un genoma pequeño, a utilizar BWA-MEM para alinear lecturas y contigs con un genoma de referencia, y a utilizar el navegador del genoma UCSC e IGV para visualizar estas alineaciones.

Los BAC pueden utilizarse para amplificar un determinado fragmento de ADN de interés dentro de bacterias. Se utilizó mucho para generar el genoma humano de referencia.

El primer paso es crear el directorio de trabajo:
\begin{lstlisting}[language=bash]
export WD=~/intro-wgs 
mkdir -p $WD
cd $WD
mkdir -p data res out log 
tree $WD
\end{lstlisting}

Ahora, como ya creamos el entorno intro-wgs con el script obtenido previamente, lo activamos mediante \texttt{conda activate intro-wgs}. Dentro del entorno podemos ver los paquetes que incluye, por ejemplo \texttt{which abyss-pe}. En este entorno se incluyen los siguientes software:
\begin{itemize}
\item bwa: short-read aligner
\item abyss: short-read assembler
\item samtools: tool to manipulate SAM format file
\item mummer: long sequence aligner
\item seqtk: toolkit for manipulating sequence data
\item igv: interactive genome visualizer
\item gnuplot: graphics library ised by mummer to generate plots
\end{itemize}

Como nos hemos descargado unos datos, o incluso los datos generados por nosotros mismos, es importante inspeccionarlos: 
\begin{lstlisting}[language=bash]
zcat data/30CJCAAXX_4_1.fq.gz | head -8

readlen=$(zcat data/30CJCAAXX_4_1.fq.gz | head -2 | sed -n 2p | awk '{print length}')
echo "Length of reads: ${readlen}bp"

nlines1=$(zcat data/30CJCAAXX_4_1.fq.gz | wc -l)
nlines2=$(zcat data/30CJCAAXX_4_2.fq.gz | wc -l)
echo "The files have $nlines1 and $nlines2 lines respectively"

nreads1=$(expr $nlines1 / 4)
nreads2=$(expr $nlines2 / 4)
total_reads=$(expr $nreads1 + $nreads2)
echo "Files have $nreads1 and $nreads2 reads, for a total of $total_reads"

nbases=$(expr $total_reads \* $readlen)
echo "Total number of bases sequenced: $nbases"

bac_length=200000
coverage=$(expr $nbases / $bac_length)
echo "Coverage of the 200kbp BAC: ${coverage}x"
\end{lstlisting}

La cobertura resultante es 2554x, por lo que es muy alta y se puede continuar con el ensamblaje. Primero, se crea un índice bwa para nuestro genoma, es decir, indexar el genoma en fragmentos para facilitar la búsqueda durante el mapeo:
\begin{lstlisting}[language=bash]
bwa index res/genome/chr3.fa
\end{lstlisting}

Ahora vamos a ensamblar nuestras lecturas en contigs usando abyss.
Usaremos un tamaño de kmer de 48 (recomendado para lecturas de 50bp), y le diremos que nuestro objetivo es un ensamblaje de 200kb.
\begin{lstlisting}[language=bash]
mkdir -p out/assembly/k48
abyss-pe -C out/assembly/k48/ name=BAC_ASSEMBLY k=48 s=200 v=-v in="$(pwd)/data/30CJCAAXX_4_1.fq.gz $(pwd)/data/30CJCAAXX_4_2.fq.gz" contigs 2>&1 | tee log/abyss.log
\end{lstlisting}

Para ver la longitud del contig más largo:
\begin{lstlisting}[language=bash]
grep -v ">" out/assembly/k48/BAC_ASSEMBLY-contigs.fa | awk '{print length}' | sort -n | tail -1
\end{lstlisting}

En el log se puede ver cuántas lecturas se han alineado durante el ensamblaje:
\begin{lstlisting}[language=bash]
grep "Mapped" log/abyss.log
\end{lstlisting}
El resultado es un 72,7\% mapeado, lo cual está bien (el límite se suele poner en 70\%).

%11/11 - Tomás di Domenico
El siguiente paso es alinear los contigs al genoma de referencia mediante BLAT. Primero obtenemos los encabezados de los contigs:
\begin{lstlisting}[language=bash]
grep ">" out/assembly/k48/BAC_ASSEMBLY-contigs.fa
\end{lstlisting}

Los contigs 93 y 96 se encuentran adyacentes. Para filtrarlos en ficheros separados, se puede utilizar samtools:
\begin{lstlisting}[language=bash]
samtools faidx out/assembly/k48/BAC_ASSEMBLY-contigs.fa 96 93 \
    > out/assembly/k48/selected_contigs.fa
\end{lstlisting}
Ahora nos vamos a \href{http://genome.ucsc.edu}{UCSC Genome Browser} y subimos el fichero que acabamos de generar. Estos contigs alinean al cromosoma 3. De hecho, el primero es un scaffold mejorado del cromosoma 3 que todavía no está incluido en el cromosoma 3 de referencia. Para ver la banda del cromosoma, en los resultados de BLAT nos vamos al visualizador, donde se especifica la banda (en este caso q27.3). En el visualizador, también se observan barras rojas en la sección de nuestros contigs. Estas barras coinciden con las barras de "Common dbSNP", que muestra las mutaciones de los contigs, y al pulsar sobre ellas, aparece la información de la base de datos dbSNP.

RepeatMasker es un programa que detecta las partes repetitivas del genoma y permite enmascararlas para que no afecten al análisis. Pulsando sobre el nombre, se expande en los distintos tipos de regiones repetitivas. En nuestro caso, los dos contigs están separados por una región repetitiva simple de TA. Hay otras regiones repetitivas en los contigs de tipo LINE o LTR, pero eso no supone ningún problema en el ensamblaje al ser regiones repetitivas del genoma, pero únicas en el fragmento. 

\section{Long read sequencing and WGS}
Como ya hemos mencionado, el uso de lecturas pequeñas es especialmente complicado cuando se trata de regiones que pueden repetirse a lo largo del genoma. Esta situación podría mejorarse considerablemente si se dispusiera de lecturas más largas que pudieran extenderse más allá de las regiones repetitivas. Las primeras máquinas que realizaron secuenciación de lectura larga fueron las de Pacific Biosciences (PacBio). Producen lecturas con una longitud media de unos 20k.

MinION, la primera máquina de Oxford Nanopore Technologies, es capaz de producir lecturas de longitud teóricamente ilimitada; el récord actual está en 2 megabases. La tecnología aprovecha una proteína de poro para secuenciar moléculas largas (no se limita al ADN). La porina se inserta en la membrana y, mediante otras proteínas, la molécula a secuenciar pasa a través de ella para su detección. A través del poro pasa una corriente estable. Cuando «objetos» atraviesan el poro, alteran esta corriente. La variación puede detectarse y su firma asociarse a un determinado «objeto» que atraviesa el poro.
Esto es análogo a entender qué rocas están bloqueando un agujero midiendo la cantidad de agua que lo atraviesa.
El ciclo de secuenciación funciona de la siguiente manera: una proteína motora une la doble cadena de ADN y ayuda a llevarla hasta el poro. Una de las hebras comienza a atravesar el poro a medida que la cadena se desenreda y, finalmente, la proteína motora sale y el ciclo se reinicia.
El proceso se desarrolla a gran velocidad, generando ingentes cantidades de datos en forma de señales eléctricas.

Esta señal se muestrea con mucha frecuencia y se toman una serie de medidas discretas. A continuación, estas mediciones se segmentan para intentar identificar diferentes tramos de secuencia de longitud k (k-mers). Esto no siempre es sencillo, ya que las diferencias en los niveles de señal consecutivos pueden ser muy pequeñas.
Tras pasar de la señal a los sucesos, el siguiente paso es traducir estos sucesos a secuencia. Esto se hace comparando el nivel de señal medido del suceso con el de una base de datos.
Aunque trabajar con k-mers hace que el tamaño de la base de datos sea mucho mayor, también nos proporciona una forma de comprobar el solapamiento entre k-mers consecutivos a medida que la secuencia se desplaza por el poro.

La secuenciación por nanoporos es un proceso de flujo continuo: se obtienen datos en cuanto se inicia la ejecución. Esto permite algunos usos exclusivos de la tecnología.
El proceso de secuenciación puede interrumpirse en cualquier momento. Se puede lavar la celda de flujo y cargar otra muestra para secuenciarla.
Se pueden realizar análisis en tiempo real de los datos transmitidos y el proceso se puede interrumpir cuando se hayan generado suficientes datos.
Se puede incluso generar una base de datos de secuencias y rechazar una molécula del poro en función de su coincidencia (o no) con dicha base de datos, con lo que a) se evita que el poro se desgaste por secuencias no deseadas y b) se eliminan secuencias no deseadas de los datos de salida.

Aparte de las largas lecturas obtenidas y de los flujos de trabajo run-until y read-until que acabamos de mencionar, el tamaño compacto de la tecnología abre la puerta a aplicaciones que antes eran imposibles.
Sin embargo, como es habitual, no todo es perfecto: las lecturas individuales de PacBio y las máquinas de nanoporos tienen una tasa de error mucho mayor que, por ejemplo, las lecturas de Illumina: 5\% frente a 0,01\%. Se necesitaría un consenso de 30 lecturas para alcanzar una precisión del 99,99\%.
Las mejoras son constantes y las actualizaciones tecnológicas periódicas siguen aumentando la precisión. Recientemente se han añadido dos puntos de chequeo para disminuir el problema de los homopolímeros.

\section{Práctica - lecturas largas}
Ahora vamos a adquirir experiencia práctica en el ensamblaje de lecturas largas.
En este caso, realizaremos un trabajo exploratorio: sin información previa sobre el experimento, descargaremos algunas lecturas generadas por una máquina de secuenciación de lecturas largas, las ensamblaremos y las mapearemos en el genoma humano. A continuación, intentaremos ver qué podemos averiguar sobre los datos.

Ahora, como ya creamos el entorno intro-wgs-long con el script obtenido previamente, lo activamos mediante \texttt{conda activate intro-wgs-long}. Dentro del entorno podemos ver los paquetes que incluye, por ejemplo \texttt{which abyss-pe}. En este entorno se incluyen los siguientes software:
\begin{itemize}
\item bwa: a sequence aligner
\item samtools: tool to manipulate SAM format file
\item assembly-stats: a tool to view stats on assemblies (and other sequence files)
\item flye: a tool for manipulating alignment files
\end{itemize}

Ahora podemos descargar y descomprimir nuestro primer conjunto de datos: una serie de lecturas largas obtenidas de una muestra humana con una máquina Promethion 2 Solo de Oxford Nanopore Technologies.
\begin{lstlisting}[language=bash]
wget -P data https://bioinformatics.cnio.es/data/courses/intro-wgs/long_reads.fastq.gz
\end{lstlisting}

El valor N50 es una de las principales estadísticas utilizadas para evaluar la calidad de un ensamblaje. En pocas palabras, cuanto mayor sea el valor N50, más largos serán los contigs.
Para calcular el N50, se toman los contigs más largos del ensamblaje y se suman sus longitudes hasta alcanzar el 50\% de la longitud total del genoma. La longitud del contig más corto de ese grupo es su valor N50.

Dado que los experimentos de secuenciación de lectura larga producen lecturas de longitud comparable a los contigs ensamblados de secuenciación de próxima generación, el estadístico N50 se utiliza habitualmente para evaluar sus resultados.

Vamos a obtener algunas estadísticas para nuestro fichero FASTQ:
\begin{lstlisting}[language=bash]
assembly-stats <(gunzip -c data/long_reads.fastq.gz)
\end{lstlisting}

Ahora estamos listos para probar un ensamblador basado en lectura larga.
Usaremos el ensamblador flye. El argumento -tle dice que utilice múltiples núcleos: en un ordenador personal lo ideal sería que se configurara con un núcleo menos que el total que tiene. --nano-hqle dice que la entrada proviene de datos de nanoporos de alta calidad (lo último en química y software). Ignoraremos -gpor ahora.
\begin{lstlisting}[language=bash]
mkdir -p log/flye
mkdir -p out/flye
flye -t 7 --nano-hq data/long_reads.fastq.gz -g 1.5m -o out/flye/ 2>&1 | tee log/flye/assembly.log
\end{lstlisting}
En el output aparece que hemos obtenido dos fragmentos. La longitud total es aproximadamente 1550000 bases, mientras que el contig más largo es aproximadamente 1540000, por lo que tenemos prácticamente un alineamiento de punta a punta salvo por un trozo pequeño. 

Ahora vamos a alinear nuestro ensamblaje con el genoma de referencia para que podamos cargarlo en el navegador del genoma de la UCSC y ver lo que tenemos. También convertiremos el SAM de salida a formato BAM y lo indexaremos.
\begin{lstlisting}[language=bash]
mkdir -p out/alignment
bwa mem -t2 ~/intro-wgs/res/genome/chr3.fa out/flye/assembly.fasta > out/alignment/assembly.sam
samtools sort -o out/alignment/assembly.bam out/alignment/assembly.sam
samtools index out/alignment/assembly.bam
\end{lstlisting}

Ahora vamos a subir nuestro archivo de alineación y su índice a Internet, para que podamos ponerlos a disposición del navegador de la UCSC como una pista personalizada.
Utilizaremos \href{https://uguu.se/}{Uguu}, un sitio web que permite subir temporalmente archivos que se borran automáticamente al cabo de 3 horas.
Sube out/alignment/assembly .bam y out/alignment/assembly.bam.bai. 

Ahora se puede copiar las URL haciendo clic en los iconos de la derecha, o haciendo clic con el botón derecho en las propias URL. A continuación, utilízalas en el siguiente código para sustituir:
\begin{lstlisting}[language=bash]
track type=bam name="My contigs" bigDataUrl=BAM_URL bigDataIndex=BAI_URL
\end{lstlisting}

A continuación, ve al navegador UCSC y haz clic en Mis datos > Pistas personalizadas, pega esa línea en la casilla PegarURL o datos y haz clic en el botón Enviar.

En la página siguiente, haz clic en el botón ir a la primera anotación. Cuando aparezca el navegador, haz clic en el botón de zoom 10x.
Si estás haciendo esta sección inmediatamente después de la lección de lecturas cortas, ya está todo listo para comparar ambos ensamblajes e intentar sacar algunas conclusiones.
Si no tienes los contigs de lecturas cortas ya cargados en el navegador, cárgalos de nuevo pegando el contenido de $\sim$ /intro-wgs/out/assembly/k48/selected\_contigs.faen UCSC BLAT, o enviando el archivo usando los botones de la sección «File Upload» de la herramienta BLAT.

%13/11 - Tomás di Domenico
\chapter{Variación estructural}
La variación estructural (también variación estructural genómica) es la variación en la estructura del cromosoma de un organismo. Consiste en muchos tipos de variación en el genoma de una especie, y suele incluir tipos microscópicos y submicroscópicos, como deleciones, duplicaciones, variantes del número de copias, inserciones, inversiones y translocaciones. Se denomina como variación estructural todo aquel cambio de secuencia que tenga más de 50 bases respecto a una referencia. Si tiene un tamaño menor, entra en los INDELs.

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7\textwidth]{figs/types-sv.png}
\caption{Distintos tipos de variación estructural.}
\end{figure}

Varios mecanismos mutacionales pueden conducir a la generación de SV. Estos pueden ocurrir tanto meiótica como mitóticamente.
\begin{itemize}
\item Error en la recombinación
\item Errores en la reparación de ADN 
\item Errores en la replicación
\end{itemize}
Cada uno de estos métodos generaría una firma molecular particular en y alrededor de los puntos de rotura del SV.

\section{Detección de variantes estructurales}
Los tipos de variantes estructurales más estudiados son los que implican cambios en el número de copias de determinados fragmentos de material genético, ya que son más fáciles de detectar con las tecnologías actuales. Estos eventos se denominan colectivamente «variación del número de copias» (CNV). La detección de otros variantes desde NGS depende de la complejidad de los algoritmos: profundidad de lectura (o profundidad de cobertura), lectura pair-end, split read, ensamblaje de novo. 

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7\textwidth]{figs/sv-detection-methods.png}
\caption{Representación visual de los distintos métodos de detección de variantes estructurales.}
\end{figure}

El uso de lecturas pequeñas es especialmente difícil cuando se secuencian áreas que pueden repetirse a lo largo del genoma. Lecturas largas pueden resolver regiones complejas al anclarse en regiones normales. 

\section{Detección de CNV}
Como ya se ha mencionado, la variación estructural relacionada con los cambios en el número de copias de las regiones genómicas es la más fácil de caracterizar con las tecnologías actuales.
Existen dos técnicas principales actualmente en uso: la hibridación genómica comparativa (CGH) y la detección de CNV basada en secuenciación (CNV-seq).

\subsection{Hibridación genómica comparativa (CGH)}
Se cogía una secuencia referencia y una muestra, marcándolas con fluorescentes distintos. Se hibridizaba, y dependiendo del color de la muestra resultante, se podía estimar la abundancia relativa. 

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7\textwidth]{figs/Comparative-genome-hybridization-CGH-microarray-Karampetsou-et-al-2014.png}
\end{figure}

\subsection{CNV-seq}
El análisis de CNV basado en la secuenciación se basa en la detección de regiones del genoma con más (ganancia) o menos (pérdida) lecturas de lo esperado.
Puede realizarse mediante secuenciación del exoma completo (WES) o del genoma completo (WGS).
La llamada WES requiere una secuenciación muy profunda (100x), mientras que la WGS ha demostrado funcionar con una cobertura tan baja como 0,1x.
Esto se debe a que disponer del genoma completo nos permite crear una base estadística de lo que es «normal». Esto no es posible con sólo el 1\% del genoma (WES).

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7\textwidth]{figs/cnv-calling-wgs.png}
\end{figure}

\subsection{CGH vs CNV-seq}
La CGH se considera el estándar dorado. Esto se debe a que para CNV-seq hay que hacer algunas suposiciones que harán que los diferentes métodos de análisis produzcan resultados potencialmente diferentes. Un ejemplo de la concordancia entre diferentes herramientas CNV-seq:

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7\textwidth]{figs/cgh-vs-cnvseq.png}
\end{figure}

\subsection{Comprensión de la salida típica de CNV-seq}
Un gráfico típico de CNV sería como el siguiente:

\begin{figure}[h!]
\centering
\includegraphics[width = 0.7\textwidth]{figs/cnv-plot.png}
\end{figure}
Los fragmentos grises son regiones sin resolver durante el ensamblado. 

El primer paso para realizar la llamada CNV es \textbf{dividir el genoma en intervalos no solapados} que cubren un determinado número de bases (por ejemplo, 50.000). Cada bin agrupa todas las lecturas que caen dentro de su área. Cuanto más pequeño sea el bin, mayor será la resolución y el detalle de los eventos CNV detectables.
El tamaño del bin (es decir, la resolución) depende de la profundidad de secuenciación, la ploidía del genoma y, en muestras de cáncer, la pureza del tumor, entre otros factores.
Cada bin se caracteriza por una relación log2, que representa la relación entre las lecturas observadas y las lecturas esperadas y el zscore para indicar su posición con respecto a la media.

El segundo paso es la \textbf{segmentación}: agrupar bins que parece que pertenecen al mismo segmento. Igual que los bins, se almacena en una tabla el ratio y el zscore. 

El paso final es la \textbf{llamada de aberraciones}, donde se asigna a los segmentos una probabilidad de ser un evento CNV verdadero mediante el zscore. La aberración es una etiqueta de eventos estadísticamente significativos. Son un subset de los segmentos que cuenta con una columna adicional que especifica si su tipo es una ganancia o una pérdida. Se utilizan colores para visualizarlo: el verde para ganancias y naranja para pérdidas. 

\section{Práctica - variantes estructurales}
En esta sección analizaremos algunas muestras utilizando WisecondorX para realizar llamadas CNV.
Comenzaremos con los resultados de los alineamientos con el genoma humano en formato BAM.
El resultado que obtengamos del llamador de CNV debería ayudarnos a arrojar algo de luz sobre la situación estructural de las muestras analizadas.

Al igual  que en las prácticas anteriores, primero se crea un entorno de conda con el software que se va a utilizar. Con el script de configuración se descargaron 10 ficheros de muestras control que se espera que no contengan eventos de CNV y dos muestras que queremos comparar. 

Ahora vamos a indexar nuestros archivos BAM, lo que es necesario para la mayoría de los análisis que hacen el acceso aleatorio de las alineaciones.
\begin{lstlisting}[language=bash]
parallel -j $(nproc) samtools index {} ::: data/*.bam
\end{lstlisting}

Ahora tenemos que convertir nuestros archivos BAM en archivos npz (archivos numpy arrays comprimidos), que es el formato que WisecondorX utilizará posteriormente.
\begin{lstlisting}[language=bash]
mkdir -p out/npz
time parallel -j $(nproc) WisecondorX convert {} out/npz/{/.}.npz ::: data/*.bam
#Alternativa: ls data/*.bam | parallel -j $(nproc) WisecondorX convert {} out/npz/{/.}.npz
\end{lstlisting}

A continuación creamos la referencia con la que comparar nuestras muestras control.
\begin{lstlisting}[language=bash]
mkdir -p out/ref
WisecondorX newref out/npz/control*.npz out/ref/reference.npz \
    --yfrac 1 --cpus $(nproc)
\end{lstlisting}

Finalmente, obtenemos las predicciones de nuestras muestras.
\begin{lstlisting}[language=bash]
mkdir -p out/predictions
parallel WisecondorX predict {} out/ref/reference.npz out/predictions/{/.} --bed --plot ::: out/npz/sample*.npz
\end{lstlisting}

En este punto, se han generado algunos plots en PNG. Tras abrirlos, vemos que los gráficos de sample1 son planos. Las nubes de puntos están extremadamente dispersas y no se puede determinar nada. En el caso de sample2, las nubes de puntos, pese a seguir siendo muy dispersas, sí permite ver algunos eventos de ganancia y pérdida. 

También podemos crear gráficos CNV basados en los resultados de WisecondorX. Para ello utilizaremos un script python personalizado.
Este script generará gráficos para los cromosomas 8, 10 y 13 de nuestras muestras.
\begin{lstlisting}[language=bash]
mkdir -p scripts
wget -P scripts https://gitlab.com/bioinfo-lessons/intro-sv/-/raw/master/scripts/plots.py
python scripts/plots.py
\end{lstlisting}

Este script genera los mismos gráficos, pero marcando algunos oncogenes como MYC. En los gráficos de los cromosomas 8, 10 y 13, se ve cómo sample2 tiene una pérdida de los supresores tumorales BRCA2 y RB1.

Ahora vamos a visualizar la salida de WisecondorX en IGV. Para ello, debemos eliminar la cabecera de los ficheros bed.
\begin{lstlisting}[language=bash]
for f in out/predictions/*.bed; do grep -v "start" $f > $(dirname $f)/$(basename $f .bed).igv.bed; done;
\end{lstlisting}
A continuación cargamos los segmentos y las aberraciones en IGV. Haciendo click derecho en cada una de las cuatro pistas, se puede seleccionar el modo de vista ampliada. 

Como conclusión de la práctica, hemos observado algunas pérdidas en genes supresores de tumores (BRCA2, RB1) y ganancias en un oncogén (Myc).
Esto indicaría que nuestra muestra afectada (sample2) procede de un paciente que padece algún tipo de cáncer, que es de hecho el origen de la muestra.
