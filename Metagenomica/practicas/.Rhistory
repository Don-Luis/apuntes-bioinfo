#Recomendable poner un título a cada bloque de código
library(dada2)
library (ggplot2)
library(plotly)
library(DECIPHER)
library(ShortRead)
library(Biostrings)
library(readr)
library("phyloseq")
library("DESeq2")
library("tibble")
library("dplyr")
library("tidyr")
library(openssl) #for the codification of ASVs nucleotide sequence into a shorter string (ASVs names)
library("vegan")
library("microbiome")
library("hrbrthemes") #scales in plots
library("RColorBrewer")
library("data.table")
# Create an output directory to store the clipped files
cut_dir <- file.path(".", "cutadapt")
if (!dir.exists(cut_dir)) dir.create(cut_dir)
fnFs.cut <- file.path(cut_dir, basename(fnFs))
#Recomendable poner un título a cada bloque de código
library(dada2) #librería con la que se determinan SV
library (ggplot2)
library(plotly) #librería que genera una máscara encima de cualquier objeto ggplot para que el gráfico sea interactivo
library(DECIPHER) #analizar disparidad entre secuencias
library(ShortRead) #interpretación archivos fasta
library(Biostrings)
library(readr) #parte de tidyverse para la interpretación de dataframes
library("phyloseq") #integración de datos y hacer todos los gráficos
library("DESeq2") #permite ver qué bacterias son las enriquecidas en una muestra con respecto a otra; calcular diversidad
library("tibble")
library("dplyr")
library("tidyr")
library(openssl) #for the codification of ASVs nucleotide sequence into a shorter string (ASVs names)
library("vegan") #hacer estudios de diversidad
library("microbiome") #estudios de diversidad
library("hrbrthemes") #scales in plots of ggplot
library("RColorBrewer") #paletas de colores de degradados
library("data.table")#conversiones en dataframes que no son posibles en dplyr
list.files(path="./fastq/", pattern ="_1.fastq")
#filename Forwards
fnFs <- sort(list.files(path="./fastq", pattern="_1.fastq", full.names = TRUE))
#filename Reverse
fnRs <- sort(list.files(path="./fastq", pattern="_2.fastq", full.names = TRUE))
# Extract sample names, assuming filenames have format: SAMPLENAME_1.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
print("Forward Files list")
fnFs
print("Reverse Files list")
fnRs
print("Sample names")
sample.names
cutadapt <-"/home/sandra/miniconda3/envs/meta-env/bin/cutadapt"
system2(cutadapt, args = "--version")
FWD<- "CCTACGGGNGGCWGCAG"
REV <- "GACTACHVGGGTATCTAATCC"
allOrients <- function(primer) {
# Create all orientations of the input sequence
require(Biostrings) #si Biostrings no está cargado, no funciona
dna <- DNAString(primer)  # The Biostrings works w/ DNAString objects rather than character vectors
orients <- c(Forward = dna, Complement = Biostrings::complement(dna), Reverse = reverse(dna),
RevComp = reverseComplement(dna))
return(sapply(orients, toString))  # Convert back to character vector
}
FWD.orients <- allOrients(FWD)
REV.orients <- allOrients(REV)
primerHits <- function(primer, fn) {
# Counts number of reads in which the primer is found
# fn = filename
nhits <- vcountPattern(primer, sread(readFastq(fn)), fixed = FALSE)
return(sum(nhits > 0))
}
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs[[1]]))
# Create an output directory to store the clipped files
cut_dir <- file.path(".", "cutadapt")
if (!dir.exists(cut_dir)) dir.create(cut_dir)
fnFs.cut <- file.path(cut_dir, basename(fnFs))
fnRs.cut <- file.path(cut_dir, basename(fnRs))
FWD.RC <- dada2:::rc(FWD) #reverse complement de forward
REV.RC <- dada2:::rc(REV) #reverse complement de reverse
names(fnFs.cut) <- sample.names
names(fnRs.cut) <- sample.names
#por esto era importante antes ordenar de forma alfabética
#Define minimum length of reads to keep after trimming
minlen <- 150
#se podría haber dejado en 200. Dada2, en algún momento, debe solapar forward y reverse de al menos 20 nucleótidos. Por tanto, poniendo 150 nucleótidos, hay 300 en total y el amplicón es de más de 400. Esto no nos vale y metemos secuencias de más, pero estas las filtramos después. Lo importante aquí es ver si pueden solapar.
# It's good practice to keep some log files so let's create some
# file names that we can use for those
cut_logs <- path.expand(file.path(cut_dir, paste0(sample.names, ".log")))
cutadapt_args <- c("-g", FWD, "-a", REV.RC,
"-G", REV, "-A", FWD.RC,
"--match-read-wildcards", #importante para la notación IUPAC, si no se pone se perderán la mayoría de las lecturas
"-n", 3, "--discard-untrimmed", "--minimum-length", minlen)
# Loop over the list of files, running cutadapt on each file.  If you don't have a vector of sample names or
# don't want to keep the log files you can set stdout = "" to output to the console or stdout = NULL to discard
for (i in seq_along(fnFs)) {
system2(cutadapt,
args = c(cutadapt_args,
"-o", fnFs.cut[i], #salida de los forward
"-p", fnRs.cut[i], #salida para los reverse
fnFs[i], fnRs[i]), #inputs
stdout = cut_logs[i])
}
#cutadapt necesita analizar forward y reverse a la vez siempre y cuando sea el mismo elemento
# quick check that we got something
head(list.files(cut_dir))
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))
#Recomendable poner un título a cada bloque de código
library(dada2) #librería con la que se determinan SV
library (ggplot2)
library(plotly) #librería que genera una máscara encima de cualquier objeto ggplot para que el gráfico sea interactivo
library(DECIPHER) #analizar disparidad entre secuencias
library(ShortRead) #interpretación archivos fasta
library(Biostrings)
library(readr) #parte de tidyverse para la interpretación de dataframes
library("phyloseq") #integración de datos y hacer todos los gráficos
library("DESeq2") #permite ver qué bacterias son las enriquecidas en una muestra con respecto a otra; calcular diversidad
library("tibble")
library("dplyr")
library("tidyr")
library(openssl) #for the codification of ASVs nucleotide sequence into a shorter string (ASVs names)
library("vegan") #hacer estudios de diversidad
library("microbiome") #estudios de diversidad
library("hrbrthemes") #scales in plots of ggplot
library("RColorBrewer") #paletas de colores de degradados
library("data.table")#conversiones en dataframes que no son posibles en dplyr
forwplot<-ggplotly(plotQualityProfile(fnFs.cut[1:length(fnFs.cut)], aggregate=TRUE) +
geom_hline(yintercept=c(15,25,35),
color=c("red","blue","green"),
size=0.5),
width =600)
# Create an output directory to store the clipped files
cut_dir <- file.path(".", "cutadapt")
if (!dir.exists(cut_dir)) dir.create(cut_dir)
fnFs.cut <- file.path(cut_dir, basename(fnFs))
fnRs.cut <- file.path(cut_dir, basename(fnRs))
FWD.RC <- dada2:::rc(FWD) #reverse complement de forward
REV.RC <- dada2:::rc(REV) #reverse complement de reverse
names(fnFs.cut) <- sample.names
names(fnRs.cut) <- sample.names
#por esto era importante antes ordenar de forma alfabética
#Define minimum length of reads to keep after trimming
minlen <- 150
#se podría haber dejado en 200. Dada2, en algún momento, debe solapar forward y reverse de al menos 20 nucleótidos. Por tanto, poniendo 150 nucleótidos, hay 300 en total y el amplicón es de más de 400. Esto no nos vale y metemos secuencias de más, pero estas las filtramos después. Lo importante aquí es ver si pueden solapar.
# It's good practice to keep some log files so let's create some
# file names that we can use for those
cut_logs <- path.expand(file.path(cut_dir, paste0(sample.names, ".log")))
cutadapt_args <- c("-g", FWD, "-a", REV.RC,
"-G", REV, "-A", FWD.RC,
"--match-read-wildcards", #importante para la notación IUPAC, si no se pone se perderán la mayoría de las lecturas
"-n", 3, "--discard-untrimmed", "--minimum-length", minlen)
# Loop over the list of files, running cutadapt on each file.  If you don't have a vector of sample names or
# don't want to keep the log files you can set stdout = "" to output to the console or stdout = NULL to discard
for (i in seq_along(fnFs)) {
system2(cutadapt,
args = c(cutadapt_args,
"-o", fnFs.cut[i], #salida de los forward
"-p", fnRs.cut[i], #salida para los reverse
fnFs[i], fnRs[i]), #inputs
stdout = cut_logs[i])
}
#cutadapt necesita analizar forward y reverse a la vez siempre y cuando sea el mismo elemento
# quick check that we got something
head(list.files(cut_dir))
rbind(FWD.ForwardReads = sapply(FWD.orients, primerHits, fn = fnFs.cut[[1]]),
FWD.ReverseReads = sapply(FWD.orients, primerHits, fn = fnRs.cut[[1]]),
REV.ForwardReads = sapply(REV.orients, primerHits, fn = fnFs.cut[[1]]),
REV.ReverseReads = sapply(REV.orients, primerHits, fn = fnRs.cut[[1]]))
forwplot<-ggplotly(plotQualityProfile(fnFs.cut[1:length(fnFs.cut)], aggregate=TRUE) +
geom_hline(yintercept=c(15,25,35),
color=c("red","blue","green"),
size=0.5),
width =600)
forwplot
revqplot<-ggplotly(plotQualityProfile(fnRs.cut[1:length(fnRs.cut)], aggregate=TRUE) +
geom_hline(yintercept=c(15,25,35),
color=c("red","blue","green"),
size=0.5),
width =600)
revqplot
# Place filtered files in filtered/ subdirectory
filtFs <- file.path(".", "cutfiltered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(".", "cutfiltered", paste0(sample.names, "_R_filt.fastq.gz"))
names(filtFs) <- sample.names
names(filtRs) <- sample.names
out <- filterAndTrim(fnFs.cut, filtFs, fnRs.cut, filtRs,
maxN=0, maxEE=c(2,5), trimLeft=c(7,0), truncLen = c(255,234), truncQ=2, rm.phix=TRUE,
compress=TRUE, multithread=TRUE) # On Windows set multithread=FALSE
out<- cbind(out, perc.cons=round(out[, "reads.out"]/out[, "reads.in"]*100, digits=2))
print("Total Reads")
sum(out[,2])
